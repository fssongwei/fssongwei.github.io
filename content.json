{"meta":{"title":"David's Blog","subtitle":"Eat, Sleep, Code, Repeat","description":"Developer. Computer & Information Science Graduate Student @ Cornell.","author":"Wei Song","url":"http://blog.david916.com","root":"/"},"pages":[{"title":"","date":"2020-07-16T15:30:02.922Z","updated":"2019-09-19T08:53:01.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.david916.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-07-16T15:31:38.588Z","updated":"2019-09-19T11:43:19.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.david916.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"从零开始用MERN搭建一个电商网站","slug":"从零开始用MERN搭建一个电商网站","date":"2020-09-20T03:43:29.934Z","updated":"2020-09-21T16:40:08.453Z","comments":true,"path":"2020/09/20/从零开始用MERN搭建一个电商网站/","link":"","permalink":"http://blog.david916.com/2020/09/20/从零开始用MERN搭建一个电商网站/","excerpt":"","text":"介绍最近接触到MERN技术栈，想做一个全栈的项目练练手。正好之前在上网课的时候有提到如何使用第三方服务如stripe搭建一个支付系统，把这个支付系统拓展一下就可以变为一个电商网站（或者二手交易网站）了。整个项目大概花了一星期不到的时间（周一到周六完成开发，周日写这篇文章），一开始以为会是一个简单的CRUD应用，然而做的时候才体会到该项目的复杂性，有很多模块之间相互影响，还有很多安全性、跨域问题需要考虑。感觉现在前端的功能还是非常强大的，基本上很多业务逻辑都可以在前端完成，然后通过api从后台获取所需数据即可，开发时间相对以往则大大缩短。该项目虽然简单，但也实现了基本的电商网站功能比如用户登录、卖家创建和管理商品，购物车功能，商品支付与结算，订单管理等功能。 Demo Source Code - Front-end Source Code - Back-end 项目结构该项目主要分为用户认证、商品、购物车、支付和订单管理五个模块，采用前后端分离的模式，前端使用axios通过api获取后端数据。前后端的文件结构如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Client├── public│ └── index.html└── src ├── actions │ ├── index.js │ └── types.js ├── components │ ├── App.js │ ├── Authentication │ │ ├── Login.js │ │ └── OAuthPanel.js │ ├── Cart │ │ ├── CartHooks.js │ │ ├── CartMenu.js │ │ ├── CartMenuItem.js │ │ └── Checkout.js │ ├── Checkout │ │ ├── CardSection.js │ │ ├── Checkout.js │ │ ├── CheckoutForm.css │ │ ├── CheckoutForm.js │ │ ├── InjectedCheckoutForm.js │ │ ├── OrderDetail │ │ │ ├── AddressForm.js │ │ │ ├── Index.js │ │ │ └── OrderList.js │ │ └── Success.js │ ├── Dashboard │ │ ├── BuyList.js │ │ ├── ComfirmShipment.js │ │ ├── FieldFileInput.js │ │ ├── IBuy.js │ │ ├── OrderDetail.js │ │ ├── SellList.js │ │ ├── hooks.js │ │ └── iSell.js │ ├── Header │ │ ├── Header.js │ │ └── HeaderMenu.js │ ├── Landing │ │ ├── Filter.js │ │ ├── Landing.js │ │ └── Searchbar.js │ ├── Message.js │ └── Products │ ├── ProductCreate.js │ ├── ProductDetail.js │ ├── ProductEdit.js │ ├── ProductForm.js │ ├── ProductHooks.js │ └── ProductList.js ├── history.js ├── hooks │ ├── useProduct.js │ ├── useProducts.js │ └── useUser.js ├── index.js ├── reducers │ ├── authReducer.js │ ├── cartReducer.js │ ├── index.js │ └── messageReducer.js ├── resources │ └── categories.js └── store.js # Server├── index.js├── middlewares│ └── requireLogin.js├── models│ ├── Cart.js│ ├── Order.js│ ├── Product.js│ ├── Transaction.js│ └── User.js├── routers│ ├── auth.js│ ├── cart.js│ ├── order.js│ ├── payment.js│ └── product.js└── services └── createPayment.js 模块设计用户数据和认证模块该模块主要负责将新用户注册到数据库，并在前端通过api获取数据时验证用户身份。这一部分为了减轻项目复杂度，我就没有实现用户名和密码注册登录，而是通过Passport.js使用Google和Facebook OAuth进行验证登录。 后端设置一个PassportConfig负责配置passport.js，注册用户，序列化和反序列化用户信息等操作 （需要先从google developer console获取client-secret和clientID，并在console中配置app url和callback url） 12345678910111213141516171819202122232425// server/passportConfig.js// 1. 创建Strategyconst gStrategy = new GoogleStrategy( &#123; clientID: process.env.GOOGLE_CLIENT_ID, // provided by GCP console clientSecret: process.env.GOOGLE_CLIENT_SECRET,// provided by GCP console callbackURL: process.env.GOOGLE_CALLBACK_URL, // need to be configured in GCP console &#125;, async (accessToken, refreshToken, profile, done) =&gt; &#123; // 用户授权后，google返回用户数据（在profile中） try &#123; // 根据profile中的googleUserId在用户数据库中查找用户 let user = await User.findOne(&#123; googleUserId: profile.id &#125;); // ... 判断用户数据库中是否存在user，如果不存在则注册一个新user &#125; catch (error) done(error); &#125;);// 2. 序列化和反序列化用户（将用户数据存储在cookie / 从cookie中提取用户数据）passport.serializeUser((user, done) =&gt; &#123; done(null, user.id);&#125;);passport.deserializeUser(async (id, done) =&gt; &#123; try &#123; let user = await User.findById(id); done(null, user); &#125; catch (error) done(error);&#125;); (补充：大陆用户无法直接使用Google服务，因此需要设置代理（如果server部署在大陆服务器上）) 12345678/ only required in dev environment since I deployed the production environment in Google App Engineif (process.env.NODE_ENV === \"development\") &#123; var HttpsProxyAgent = require(\"https-proxy-agent\"); const agent = new HttpsProxyAgent( process.env.HTTP_PROXY || \"YOUR_PROXY_ADDRESS\" ); gStrategy._oauth2.setAgent(agent);&#125; 设置登录和callback路由 123456// server/routers/auth.jsrouter.get(\"/auth/google\", passport.authenticate(\"google\", &#123; scope: [\"profile\"] &#125;));router.get( \"/auth/google/callback\", passport.authenticate(\"google\"), // 认证并设置cookie (req, res) =&gt; res.redirect(`$&#123;process.env.CLIENT_BASE_URL&#125;`); // 重定向至前端URL); 用户在前端登录时跳转到/auth/google，会重定向至google验证页面。用户完成授权后，会从验证页面重定向回/auth/google/callback并携带授权码code，然后passport使用code获取用户profile等信息，完成用户认证或注册，设置cookie并重定向回前端相应页面。 12345678910// 登录routerouter.get(\"/auth/user\", (req, res) =&gt; &#123; if (req.isAuthenticated()) res.status(200).send(req.user._doc); else res.status(401).send(&#123; msg: \"User is not login!\" &#125;);&#125;);// 退出登录routerouter.get(\"/auth/logout\", (req, res) =&gt; &#123; req.logOut(); res.status(200).send(&#123; msg: \"Log out success!\" &#125;);&#125;); 前端在Landing Page，以及每个需要登录后才可访问的页面组件中调用GET /auth/user API检查用户登录情况，并将用户数据以全局的方式存储在redux中，以供后续组件访问 Action Creator 1234567// client/src/actions/index.jsexport const fetchAuthStatus = () =&gt; async (dispatch) =&gt; &#123; try &#123; const user = await axios.get(`$&#123;process.env.REACT_APP_API_BASE_URL&#125;/auth/user`); dispatch(&#123; type: FETCH_AUTH_STATUS, user: user.data &#125;); &#125; catch (error) dispatch(&#123; type: FETCH_AUTH_STATUS, user: false &#125;);&#125;; Reducer 1234const authReducer = (state = [true, null], action) =&gt; &#123; if (action.type === FETCH_AUTH_STATUS) return [false, action.user]; return state;&#125;; OAuth登录具体原理可以在我之前的blog (link)中查看。 商品模块这部分主要涉及商品的CRUD操作，相对比较基础，不过也涉及到一些redux-form表单等技术的使用，同时还实现了fuzzy-search模糊检索的功能 商品数据结构 123456789const productSchema = new mongoose.Schema(&#123; owner: &#123; type: mongoose.Schema.Types.ObjectId, ref: \"User\" &#125;, // 创建者 name: String, // 商品名 intro: String, // 商品介绍 price: Number, // 商品单价 quantity: Number, // 库存数量 category: String, // 商品分类 pics: [String], // 商品图片URL列表&#125;); 商品列表获取 这里我设置了一个query参数，以便前端获取商品列表时筛选所需数据。e.g. 设置query={category: &quot;sport&quot;}可以指定获取category为sport的数据，query={term: &quot;iphone 12&quot;}可以执行fuzzy search等 因为前端在多处可能会用到商品列表，所以我写了一个通用化的ProductList组件（篇幅太长就不在这放代码，路径为/client/src/components/Products/ProductList.js link） 具体而言，该组件从上层组件中接收一个query props，并从redux中获得user登录数据，以及两个action creator popMessage &amp; setCartItem 分别负责弹出提示和添加购物车（后续会补充）。该组件使用一个products hook通过调用异步api获取数据： 123456789101112131415161718// client/src/components/hooks/useProducts.jsconst useProducts = (query) =&gt; &#123; const [products, setProducts] = useState(null); const [loading, setLoading] = useState(true); useEffect(() =&gt; &#123; const fetchProducts = async () =&gt; &#123; try &#123; const response = await axios.get(`$&#123;process.env.REACT_APP_API_BASE_URL&#125;/products`, &#123;params: query,&#125; ); setProducts(response.data); setLoading(false); &#125; catch (error) throw error; &#125;; fetchProducts(); &#125;, [query]); return [loading, products];&#125;; 后端route 12345678910router.get(\"/products\", async (req, res) =&gt; &#123; try &#123; let products = &#123;&#125;; // fuzzy search 这里需要安装mongoose_fuzzy_searching包并设置对应的Product Schema if (req.query.term === \"\") products = await Product.find(); else if (req.query.term) products = await Product.fuzzySearch(req.query.term); else products = await Product.find(req.query); res.status(200).send(products); &#125; catch (error) res.status(500).send(error);&#125;); 显示商品信息 使用一个product hook异步调用GET /product/:id API获取具体的商品数据，并使用一个ProductDetail组件显示商品数据 注意这里ProductDetail组件同时通过redux接收user信息，判断如果该商品由该登录用户所创建，则显示修改商品的按钮，反之则显示添加购物车按钮 另外还使用了react-material-ui-carousel库用于滚动播放产品图片 useProduct Hook 1234567891011121314151617const useProduct = (productId) =&gt; &#123; const [product, setProduct] = useState(null); const [loading, setLoading] = useState(true); useEffect(() =&gt; &#123; const fetchProduct = async () =&gt; &#123; try &#123; const response = await axios.get( `$&#123;process.env.REACT_APP_API_BASE_URL&#125;/products/$&#123;productId&#125;` ); setProduct(response.data); &#125; catch (error) console.log(error); setLoading(false); &#125;; fetchProduct(); &#125;, [productId]); return [loading, product];&#125;; GET Product route 123456789router.get(\"/products/:id\", async (req, res) =&gt; &#123; try &#123; let product = await Product.findById(req.params.id); if (!product) res.status(404).send(&#123; msg: \"Product not found\" &#125;); else res.status(200).send(product); &#125; catch (error) &#123; res.status(500).send(error); &#125;&#125;); 创建和修改商品 创建和修改可以在前端共享一个ProductForm表单组件，通过使用redux-form管理该表单。 对于修改表单，则可设置reduxForm的enableReinitialize为true，通过使用useProduct Hook获取product数据后作为initialValues props传入到ProductForm组件中即可。共享该表单组件可以减轻许多任务量。 另外在后台需要设置两个middlewares requireLogin 和 productUpdateCheck 来检验用户是否登录，用户是否有权限修改该商品，以及用户所更新的信息是否合法等： 1234567891011121314const requireLogin = (req, res, next) =&gt; &#123; if (req.isAuthenticated()) next(); else res.status(400).send(&#123; msg: \"Unauthorize access!\" &#125;);&#125;;const productUpdateCheck = (req, res, next) =&gt; &#123; let product = req.body; if (!product.name || !product.intro || !product.price ||!product.quantity ||!product.pics ||!product.category) &#123; res.status(400).send(&#123; msg: \"Invalid product submit!\" &#125;); &#125; product.owner = req.user; // add product owner req.product = product; next();&#125;; 删除商品 该部分比较简单，只需要从数据库中找到商品，验证商品是否由该用户创建，并删除即可。通过使用一个productOwnershipCheck验证该商品的发布者 购物车模块这个模块设计到与其他多个模块之间（如用户数据模块、商品模块和后面支付模块）的数据交互，即这些模块都可以影响到购物车模块中的数据，比如用户可以在商品模块中将商品添加到购物车，支付模块需要提取购物车中的商品数据进行结算，同时购物车需要将其中的商品数据定时上传到用户数据模块，以供用户下次登录时使用。个人感觉该模块是这个商城应用中最复杂也是最容易出bug的部分。该模块的数据通过redux存储在store中以供全局访问 支付模块该模块主要使用stripe.js实现支付功能，需要比较强的安全性。用户点击check out按钮后，从redux中提取购物车的数据，并让用户填写送货地址表单。之后后端需要验证该交易是否合法（验证商品信息和金额等是否被篡改），然后使用stripe创建一个新的支付订单，用户在前端通过stripe完成支付后，后端服务器通过webhook收到stripe发来的订单确认信息，并将订单标记为“已支付”状态 订单管理模块网站部署和跨域问题该电商网站（iShop）前后端是分离的，前端使用React并部署在Vercel上（shop.wei.ai），后端用Express搭建并部署在Google App Engine上（shop-api.wei.ai）。其实一开始后端本来是部署在Heroku上的，后面在开发的过程中遇到一些跨域问题，即safari浏览器仅接受来自相同域名的跨域api调用，heroku的免费版又不支持自建域名和https。刚好之前GCP新用户注册还剩小半年免费期，就先部署在GCP了。当然缺点也是蛮明显的，就是国内用户访问很慢。以后可能会考虑将应用迁移到位于境内的服务器上。 （另外打个小广告，我最近注册了wei.ai域名，欢迎大家有空访问并提出意见） 图片上传模块 未完待续。。。","categories":[{"name":"Note","slug":"Note","permalink":"http://blog.david916.com/categories/Note/"}],"tags":[{"name":"Express","slug":"Express","permalink":"http://blog.david916.com/tags/Express/"},{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"},{"name":"React","slug":"React","permalink":"http://blog.david916.com/tags/React/"}]},{"title":"Travel to the Northwest of China Vlog","slug":"西北游vlog","date":"2020-09-07T13:53:52.644Z","updated":"2020-09-07T14:56:09.493Z","comments":true,"path":"2020/09/07/西北游vlog/","link":"","permalink":"http://blog.david916.com/2020/09/07/西北游vlog/","excerpt":"","text":"I recently traveled to Ningxia and Shaanxi provinces in China with my undergrad roommates and friends. I have been to the desert in Zhongwei city (中卫), the museum of Terracotta Army (兵马俑), and Mount Hua (华山). This vlog is automatically generated by the iPhone photos app, which is awesome. Vlog link","categories":[{"name":"Life","slug":"Life","permalink":"http://blog.david916.com/categories/Life/"}],"tags":[]},{"title":"一次关于express sameSite cookies的debug","slug":"一次关于express sameSite cookies的debug","date":"2020-08-25T15:31:28.082Z","updated":"2020-09-21T03:57:49.369Z","comments":true,"path":"2020/08/25/一次关于express sameSite cookies的debug/","link":"","permalink":"http://blog.david916.com/2020/08/25/一次关于express sameSite cookies的debug/","excerpt":"","text":"最近在写一个google / facebook oauth登录系统，前端使用react，后端使用nodejs + express，前后端分别部署在vercel和heroku上，不可避免的遇到很多跨域问题。 今天在将本地代码deploy到生产环境的时候，发现google oauth虽然能成功调用callback url重定向到后端，后端也能设置cookie，但后续的api操作却没有带上之前返回的cookie，导致无法通过api获取用户数据等信息。然而之前在开发环境测试的时候，api操作确实带上了cookie并成功获取数据，并且： 在开发和生产环境中后端都设置了cors({ credentials: true, origin: process.env.CLIENT_BASE_URL }) 前端axios获取api数据时也设置了axios.defaults.withCredentials = true; 生产环境中前端地址localhost:3000和后端地址localhost:5000同属于跨域，但测试正常 查看console，发现以下错误信息： 1234567A cookie associated with a cross-site resource at http://MYAPI.URL was setwithout the `SameSite` attribute. A future release of Chrome will only deliver cookies with cross-site requests if they are set with `SameSite=None` and `Secure`. You can review cookies in developer tools under Application&gt;Storage&gt;Cookies and see more details at https://www.chromestatus.com/feature/5088147346030592 and https://www.chromestatus.com/feature/5633521622188032. 搜索后发现，该错误是由于chrome等浏览器最近的安全升级导致，该升级要求所有跨域cookie操作都必须要对cookie设置为samesite=&quot;none&quot;和secure=&quot;true&quot;，而且该升级只针对于host不同的情况，其余跨域诸如端口号等不受到影响，这也解释了为什么开发环境测试通过而生产环境出现错误。 MDN参考 后续设置express-session 12345678910const sessionConfig = &#123; secret: process.env.SESSION_SECRET, resave: false, saveUninitialized: false, cookie: &#123; sameSite: \"none\", secure: true &#125;,&#125;;app.use(session(sessionConfig)); 修改后新问题又来了，这次后端直接不设置cookie了，即response中不包含set-cookie。查阅文档后发现当设置cookie为secure时，需要通过https设置cookie，使用http将默认不设置cookie。因此express加多一行代码 1app.set('trust proxy', 1) // trust first proxy 这次在生产环境测试成功，但生产环境的前后端地址都是由第三方提供的https地址，不知道为何也会出现这样的问题，猜想可能需要自行配置有效证书。 Update on 2020-09-21 上述问题其实是由于苹果safari浏览器的最新安全策略所导致的，现时safari浏览器无论是否设置cookie为secure或使用https，都仅允许同一域名下的跨域异步操作，在Google Chrome和Firefox浏览器测试中不存在上述问题。将server (https://shop-api.wei.ai) 和client (https://shop.wei.ai) 部署到同一域名下后问题解决。","categories":[{"name":"Debug","slug":"Debug","permalink":"http://blog.david916.com/categories/Debug/"}],"tags":[{"name":"Nodejs","slug":"Nodejs","permalink":"http://blog.david916.com/tags/Nodejs/"},{"name":"Express","slug":"Express","permalink":"http://blog.david916.com/tags/Express/"},{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"}]},{"title":"使用Passport.js实现Google OAuth登录","slug":"使用Passport.js实现Google OAuth登录","date":"2020-08-20T09:03:26.227Z","updated":"2020-08-21T12:18:44.773Z","comments":true,"path":"2020/08/20/使用Passport.js实现Google OAuth登录/","link":"","permalink":"http://blog.david916.com/2020/08/20/使用Passport.js实现Google OAuth登录/","excerpt":"","text":"Source Code Google OAuth 2.0 登录流程 client向server发起GET /auth/google请求 server将client重定向至google oauth登录页https://accounts.google.com/o/oauth2/auth，并附带以下查询参数集： response_type: code 登录后返回授权码 client_id: GOOGLE_CLIENT_ID Google控制台中的client_id，用于google识别应用程序 redirect_url: http://www.example.com/auth/google/callback 回调URL，必须和Google控制台中设置的回调URL一致 scope: [&#39;profile&#39;, &#39;email&#39;] 用户授权使用的数据返回，显示在oauth登录确认页中 用户在登录页授权登录后，google api server会将client重定向至之前设定的回调URL，并附带authorization code授权码 server收到针对回调URL的GET请求GET /auth/google/callback，从中提取出code授权码，并使用该code向google api server换取access token 请求地址：https://www.googleapis.com/oauth2/v3/token 请求参数 code: 之前获得的授权码 grant_type: authorization_code：指明使用授权码进行验证 client_id，同上 client_secret，同上 redirect_url，同上 返回值： access_token：用于获取其他google api数据或控制权 expires_in：过期时间 token_type：指明token类型 id_token：一串加密信息，使用base64 decode解密后可以获得用户邮箱email和用户唯一标识符sub等信息 refresh_token：access_token过期后，可以使用refresh_token来重新获取新的access_token，而不需要用户重新授权 可以将上述token信息保存到数据库，即使用户不使用app时也能获取用户信息和代替用户进行google api操作等 server从google api收到用户数据后，可以将用户注册到数据库，然后将用户信息序列化后设置cookie并返回给client，后续client使用该cookie进行身份验证 使用passport middleware可以帮助我们简化中间与google api交互的流程，我们只需要设置以下组件： GoogleStrategy：设置clientID，clientSecret和callbackURL verify / register callback function：接收用户数据，并完成后续用户认证和注册等流程 session serialization / deserialization：将用户信息存储到cookie/从cookie解码用户信息 next middleware（或router的callback function）：执行后续api数据返回 passportJS google oauth workflow.jpg 创建google strategy 1234567891011// passport-config.jslet myGoogleStrategy = new GoogleStrategy(&#123; clientID: GOOGLE_CLIENT_ID, clientSecret: GOOGLE_CLIENT_SECRET, callbackURL: \"http://www.example.com/auth/google/callback\" &#125;, function(accessToken, refreshToken, profile, done) &#123; User.findOrCreate(&#123; googleId: profile.id &#125;, function (err, user) &#123; return done(err, user); &#125;);&#125;); 123// index.jsconst passport = require(\"passport\");require(\"./passportConfig\"); Ref1 Ref2 cookie验证流程 session workflow.jpg Express-session middleware：用于解码从client发来的cookie 123456789// index.jsconst session = require(\"express-session\");app.use( session(&#123; secret: process.env.SESSION_SECRET, resave: false, saveUninitialized: false, &#125;)); passport.initialize() middleware：负责从cookie中提取userId 12// index.jsapp.use(passport.initialize()); app.use(passport.session())：使用userId，从数据库中获取user，或将user序列化为cookie 12345678910111213// passport-config.jspassport.serializeUser((user, done) =&gt; &#123; done(null, user.id);&#125;);passport.deserializeUser(async (id, done) =&gt; &#123; try &#123; let user = await User.findById(id); done(null, user); &#125; catch (error) &#123; done(error); &#125;&#125;); 12// index.jsapp.use(passport.session()) Self-defined middleware：使用req.isAuthenticated()函数验证登录 12345678middlewares.checkAuthenticated = async (req, res, next) =&gt; &#123; if (req.isAuthenticated()) &#123; next(); &#125; else &#123; req.flash(\"error\", \"You need to login first\"); res.redirect(\"/auth/login\"); &#125;&#125;","categories":[{"name":"Note","slug":"Note","permalink":"http://blog.david916.com/categories/Note/"}],"tags":[{"name":"Nodejs","slug":"Nodejs","permalink":"http://blog.david916.com/tags/Nodejs/"},{"name":"Express","slug":"Express","permalink":"http://blog.david916.com/tags/Express/"},{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"}]},{"title":"React APIs Widget","slug":"React APIs Widget","date":"2020-08-05T03:31:25.319Z","updated":"2020-08-05T08:38:54.009Z","comments":true,"path":"2020/08/05/React APIs Widget/","link":"","permalink":"http://blog.david916.com/2020/08/05/React APIs Widget/","excerpt":"","text":"IntroductionThis React app contains four different widgets: A translate widget using Google Translate API A wiki search widget using Wikepedia API A photo search widget using Unsplash API A youtube widget using Youtube Data API v3 Other tools &amp; libraries include: Bootstrap Material Design - UI Library Axios - HTTP Library Faker.js - Random String Generator Live DemoSource Code","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"},{"name":"React","slug":"React","permalink":"http://blog.david916.com/tags/React/"}]},{"title":"在React中实现Debounced Textfield","slug":"React: Debounced Textfield","date":"2020-08-03T12:15:26.026Z","updated":"2020-08-03T12:57:05.003Z","comments":true,"path":"2020/08/03/React: Debounced Textfield/","link":"","permalink":"http://blog.david916.com/2020/08/03/React: Debounced Textfield/","excerpt":"","text":"Introduction假设我们需要实现一种类似google的搜索提示功能，即用户输入搜索词的过程中，输入框的下方会同步显示搜索的候选项： 基本方案：通过input的onChange listener监听input field文本的变化，并通过调用api返回提示结果 存在问题：每次用户输入或删除一个字符，即调用一次API，造成资源浪费。我们希望可以设置一个timer，当用户停止输入一段时间后，才调用api并返回结果 Solution workflow.png 设置两个state，分别为text和debouncedText 每当event listener监听到变化，调用setText函数重设state中的text 使用useEffect监听text的变化，并执行以下步骤 设定一个timer，延迟一段时间（500ms）后使用text和setDebouncedText函数来设置debouncedText的值 返回一个useEffect cleanup funtion来删除这个timer。这个cleanup function将会在下一次text发生变化时调用并清理掉上一次设置的timer。 假设当前text和debouncedText字符串为”abc”，用户分别再输入’d’和’e’，此时存在两种情况： 当用户两次键入字符时间小于500ms时，前一次timer的设定时间还没到而不会产生更新，而后面cleanup funtion会清理掉前面设置的timer，因此debouncedText的值不变，仍为”abc” 当用户两次键入字符时间大于500ms时，前一次timer已到时，会调用setDebounced来更新debouncedText的值，此时为”abcd” 使用另一个useEffect监听debouncedText的变化，并完成api等操作 Code1234567891011121314151617181920212223242526// DebouncedTextField.jsimport React, &#123; useState, useEffect &#125; from \"react\";const DebouncedTextField = (&#123; initText, onTextChange &#125;) =&gt; &#123; const [text, setText] = useState(initText); const [debouncedText, setDebouncedText] = useState(initText); useEffect(() =&gt; &#123; const timerID = setTimeout(() =&gt; &#123; setDebouncedText(text); &#125;, 500); return () =&gt; &#123; clearTimeout(timerID); &#125;; &#125;, [text]); // debouncedText发生变化后调用onTextChange执行后续api操作等 useEffect(() =&gt; onTextChange(debouncedText), [debouncedText, onTextChange]); return ( &lt;input type=\"text\" onChange=&#123;(e) =&gt; setText(e.target.value)&#125; value=&#123;text&#125; /&gt; );&#125;;export default DebouncedTextField;","categories":[{"name":"Note","slug":"Note","permalink":"http://blog.david916.com/categories/Note/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"},{"name":"React","slug":"React","permalink":"http://blog.david916.com/tags/React/"}]},{"title":"React：一次关于onclick的debug","slug":"React：一次关于onclick的debug","date":"2020-08-02T14:07:59.318Z","updated":"2020-08-02T14:13:26.525Z","comments":true,"path":"2020/08/02/React：一次关于onclick的debug/","link":"","permalink":"http://blog.david916.com/2020/08/02/React：一次关于onclick的debug/","excerpt":"","text":"React中可以向onClick（onSubmit，onChange等同理）中传入一个函数，这个函数会在组件被click时执行： 123&lt;button onClick=&#123;() =&gt; &#123; // some code to execute after button clicked&#125;&#125;&gt; 这个函数可以接受一个参数，即event： 1234&lt;button onClick=&#123;(event) =&gt; &#123; // some code to execute after button clicked // you can use event object to do something, such as event.target.value&#125;&#125;&gt; 同时也可以在函数体中使用该component内，该函数外定义的其他变量，且这些变量不需要通过该函数的参数传入，e.g. 12// 假设外部定义了一个名为item的state变量，还有一个从上层component传递下来的callback函数 cbfunc() 需要使用该item变量&lt;button onClick=&#123;() =&gt; cbfunc(item)&#125;&gt; 下面这种写法是错误的，即不需要将item作为参数传入，且第一个传入的参数会被当成event对象 1&lt;button onClick=&#123;(item) =&gt; cbfunc(item)&#125;&gt;","categories":[{"name":"Debug","slug":"Debug","permalink":"http://blog.david916.com/categories/Debug/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"},{"name":"React","slug":"React","permalink":"http://blog.david916.com/tags/React/"}]},{"title":"Youtube Shuffle","slug":"Youtube Shuffle","date":"2020-07-29T11:40:22.751Z","updated":"2020-08-05T05:54:30.984Z","comments":true,"path":"2020/07/29/Youtube Shuffle/","link":"","permalink":"http://blog.david916.com/2020/07/29/Youtube Shuffle/","excerpt":"","text":"IntroductionLive Demo Source Code Youtube shuffle is a React app using Youtube Data API. It has a personalized user interface which allows users to search a Youtube video and play it. It also includes a shuffle function, which the program will randomly generated a keyword and presents the related videos from Youtube. Youtube Shuffle.png Technologies and libraries using in this project are listing below: Front-end Library: React UI Library: MDUI APIs: Youtube Data API v3 Other Libraries: Faker.js (to generate random keywords) This project was bootstrapped with Create React App.","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"},{"name":"React","slug":"React","permalink":"http://blog.david916.com/tags/React/"}]},{"title":"Yelp Camp - A full-stack Node.js Web Application Project","slug":"Yelp Camp - A full-stack Node.js Web Application Project","date":"2020-07-19T09:35:53.138Z","updated":"2020-07-19T11:27:00.820Z","comments":true,"path":"2020/07/19/Yelp Camp - A full-stack Node.js Web Application Project/","link":"","permalink":"http://blog.david916.com/2020/07/19/Yelp Camp - A full-stack Node.js Web Application Project/","excerpt":"","text":"IntroductionYelp Camp is a Yelp-like node.js web app. It’s the final course project of the Web Develop Bootcamp course in Udemy. Users and campground owners can upload their campground information to the website, and other users can leave a comment to the campground. Live DemoSource Code The app is built on Node.js with Express. Other technologies and library using in this project are listing below: UI Library: Bootstrap Database: MongoDB, Mongoose Authentication: passport.js, bcrypt, express-session, express-flash Updates2020.7.19 Version 1.0 Front-end development with HTML/CSS/JS and Bootstrap 4 Back-end development with Node.js and Express Built user login and register system with Passport.js Developed Posts module and Comments module To-do ListOther features comming. If you have any idea, send email to ws446@cornell.edu Fuzzy Search Campground location with Google Maps User profile Password reset Image upload with multer and cloudinary Payment with Stripe API Ratings Pagination in campgrounds index Demo mainpage.png camppage.png","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Nodejs","slug":"Nodejs","permalink":"http://blog.david916.com/tags/Nodejs/"},{"name":"Express","slug":"Express","permalink":"http://blog.david916.com/tags/Express/"},{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://blog.david916.com/tags/Bootstrap/"}]},{"title":"Dwitter - A Twitter-like Social Media App","slug":"Dwitter - A Twitter-like Social Media App","date":"2020-07-16T23:17:00.000Z","updated":"2020-07-19T11:26:48.150Z","comments":true,"path":"2020/07/17/Dwitter - A Twitter-like Social Media App/","link":"","permalink":"http://blog.david916.com/2020/07/17/Dwitter - A Twitter-like Social Media App/","excerpt":"","text":"IntroductionDwitter is a Twitter-like social media web app written in Javascript. The name “Dwitter” stands for “David’s Twitter”. Users can post their thoughs, follow other user, comment and like other user’s posts. Live DemoSource Code The app is built on Node.js with Express. Other technologies and library using in this project are listing below: UI Library: MDUI Database: MongoDB, Mongoose Authentication: passport.js, bcrypt, express-session, express-flash Updates2020.7.16 Version 1.0(The app is officially for public testing) Improve UI with MDUI (Material Design UI) Add following &amp; unfollowing features Add like &amp; unlike features Implement express-flash to show flash message 2020.7.15 Authentication with passport.js Refactor the code 2020.7.14 Initialize the project by setting up the routers and database models Add Basic UI with HTML &amp; CSS Add posts &amp; comments create and delete features To-do ListOther features comming. If you have any idea, send email to ws446@cornell.edu Implement photo library for user to upload their photos Display the number of favorite for each post Implement google / facebook login User can change their own avatars Routers refactor Demo","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Nodejs","slug":"Nodejs","permalink":"http://blog.david916.com/tags/Nodejs/"},{"name":"Express","slug":"Express","permalink":"http://blog.david916.com/tags/Express/"},{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"}]},{"title":"Web Develop Bootcamp Front-end Projects","slug":"Web Develop Bootcamp Front-end Projects","date":"2020-06-21T22:22:00.000Z","updated":"2020-07-19T12:13:44.636Z","comments":true,"path":"2020/06/22/Web Develop Bootcamp Front-end Projects/","link":"","permalink":"http://blog.david916.com/2020/06/22/Web Develop Bootcamp Front-end Projects/","excerpt":"","text":"Below are some of the web developer bootcamp course projects. All of them are purely front-end app with only HTML / CSS / Javascript Source Code Color Guessing GameThe game will give an RGB value and some squares fill with different color. The player choose the correct color square that matches the given RGB value wins. There are three difficulty level to choose. The game also includes a statistics function to calculate the correct rate of the player. colorGame.png Demo To-Do ListThis tool allows user to keep track of their daily tasks. User can update a task, mark it as completed, or delete a task. TodoList.png Demo PatatapPatatap is a fun music game. User can type any key on their keyborad and the game will play different sounds and show animated circle on the screen with different colors. Several javacript library are included in this project, includes JQuery, Paper.js and Howler.js Demo","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://blog.david916.com/tags/Javascript/"},{"name":"HTML","slug":"HTML","permalink":"http://blog.david916.com/tags/HTML/"},{"name":"CSS","slug":"CSS","permalink":"http://blog.david916.com/tags/CSS/"}]},{"title":"Princeton Algorithm 1 Note","slug":"Princeton Algorithm 1 Note","date":"2020-04-16T08:41:25.000Z","updated":"2020-08-03T07:11:13.500Z","comments":true,"path":"2020/04/16/Princeton Algorithm 1 Note/","link":"","permalink":"http://blog.david916.com/2020/04/16/Princeton Algorithm 1 Note/","excerpt":"","text":"Week 1. Dynamic Connectivity 动态连通性 将所有对象映射为0-N证明：一棵树上的节点x的深度最多为lgN两棵树大小相等时，union操作会使合并得来的新树大小翻倍，但是高度只+1（也可以理解为每次树的高度+1，树的大小则翻倍）因此假设树最开始只有一个节点，经过lgN次翻倍后形成完整的节点数为N的树，此时树的高度为lgN! ReferenceExercises Solution 3-sum算法upper bound为O(N^2logN) （二分查找logN * N^2）lower bound至少为Ω(N) （有可能更高，但目前没有证明）因为算法至少需要遍历一遍所有数字，否则可能会漏过 证明一个算法是最优的（或者优化一个算法），要不降低算法的upper bound，要不证明算法有更高的lower bound（即缩短上下bound之间的gap）当upper bound = lower bound即证明算法没有其他更优解 Big O记号常常用来表示一个算法的性能，但这是错误的，他只表示一个算法的上界。比如：函数$2n^2$，$25000n^3$都可以用$O(n^3)$表示。改用tilde标记 ~$2n^2$来表示特定算法的性能 内存使用 Types Bytes Types Bytes char 2 char[] 2N + 24 (Overhead) int 4 int[] 4N + 24 (Overhead) double 8 double[] 8N + 24 (Overhead) boolean 1 char[][] ~ 2NM float 4 int[][] ~ 4NM long 8 double[][] ~ 8NM Java对象 Obejct：Object Overhead: 16 BytesPadding: 填充字节，使得整个object的大小为8的倍数Object的大小= 16 (Overhead) + 变量大小 + Paddinge.g. 下面类产生的object有32个字节：16(overhead) + 4*3(variables) + 4(padding) 12345public class Date &#123; private int day; private int month; private int year;&#125; 指针大小 (reference)：8 Bytes (64位) / 4 Bytes (32位) Week 2. Stack &amp; Queue 堆栈和队列resizing array如果每添加一个数字，将array扩大1位，则插入N个数据的数组的访问次数为1 + 2 + … + N ~ 0.5 N^2 Loitering问题将数组某项设为null，如A[0] == null，可以释放相应的空间 （Stack的array实现中，push操作后需要把相应位置设为null） Optimal Soultion:初始设array大小为1，每次array将满的时候，将array扩大一遍此时array的访问次数大概为 N + (1 + 2 + 4 + 8 + … + N) = ~3N当数组只有1/4满的时候，才将数组大小减半 （防止thrashing抖动问题） Performancepush 和 pop 操作最好情况下性能为O(1)由于resizing操作，最坏情况（worst case）下性能为O(N)（对比linkedlist实现，最好最坏情况均为O(1)） Memory Usage对stack的Linkedlist实现，需要空间为 40N Bytes （一个节点40 Bytes）对array实现，当数组全满时，空间为8N，当数组为1/4满时，空间为32N LinkedList vs Resizing Array链表实现，每个操作都是常数操作，但需要额外空间和用于分配空间的时间，因此平均性能较慢，但比较稳定数组实现，所需空间和运行总时间较少，但可能某个操作遇到需要resize的情况导致效率变慢，性能较不稳定 Java Generics (Java泛型)之前设计的都是String类型的stack和queue，如果我们想要实现任何数据类型都可以接收的stack和queue，就需要用到java泛型 Example：创建一个泛型的stack类： 1234567891011121314public class stack&lt;Item&gt; &#123;//这里预先定义一个Item的数据类型，以后使用的时候可以替换为其他数据类型 private class Node &#123; Item item; //这里引用Item，表示任意传入的数据类型 Node next; &#125; public Item pop() &#123; ... &#125; ... //其他函数或变量 &#125; 如果要使用这个类的对象，可以使用Stack&lt;Integer&gt; integerStack = new Stack&lt;Integer&gt;();命令创建一个接受Integer的stack对象 注意：Java不能创建泛型数组如果需要将上面的stack改为数组实现，则可以创建一个Object数组，再将其cast强制转换为Item[]类型的数组：Item[] S = (Item[]) new Object[capacity]; 另外，Java泛型只接受包装数据类型（Wrapper Type），如Integer，String，Double，基本类型（Primitive Type，如int, double）需要转换为包装类型才能用于泛型在一些高版本的java支持Autoboxing(自动打包)，可以直接传入基本数据类型 Iterator 迭代器Java提供了一种Iterator迭代器机制，可以帮助我们遍历一个class中的所有元素（比如说遍历stack和queue中的元素） 步骤（以stack为例）： 创建一个stack类，并实现（implement）iterable接口 123public class Stack &lt;Item&gt; implements Iterable&lt;Item&gt; &#123; &#125; 这里，Iterable&lt;Item&gt;里面的Item是你要迭代(遍历)的元素的数据类型 要实现这个Iterable接口，代表这个stack类中需要有一个iterator函数，这个函数返回一个类型为Iterator&lt;Item&gt;的实例(即返回一个迭代器实例，这样Java每次调用迭代机制的时候会调用这个iterator()函数生成一个新的迭代器) 123public Iterator&lt;Item&gt; iterator() &#123; return new ListIterator();&#125; 用一个内部类来实现(implement)我们的迭代器 123456789private class ListIterator implements Iterator&lt;Item&gt; &#123; public boolean hasNext() &#123; ... //确定是否能继续迭代 &#125; public Item next() &#123; ... //返回下一个元素 &#125;&#125; 注意这里Iterator&lt;Item&gt;是已经预置在Java里面的内部类（其实是一种较为特殊的类称为Interface 接口），类似于一个迭代器模板，我们需要的是创建一个新的迭代器类，但是要按照这个迭代器模板实现（所以是implements Iterator&lt;Item&gt;）因为Iterator这个类名已被占用，所以我们创建的新的迭代器类不能命名为Iterator（这里命名的为ListIterator） Example假设我们有一个stack对象Stack&lt;String&gt; ourNewStack = new Stack&lt;String&gt;()，并且这个stack类实现了iterator当我们执行语句 for (String item : ourNewStack)时： Java首先调用这个类中的iterator()函数来创建一个新的Iterator实例，这个实例里面包含hasNext() 和 next()两个methods Java首先调用hasNext()来判断是否有下一个元素，再调用next()来返回下一个元素，直到所有元素遍历完成 Bag 包利用迭代器可以实现一种名为Bag的数据结构，可以将item放入bag，然后遍历所有放入bag中的item Week 3. Sort Algorithm 排序算法Ref: Comparable接口假设我们新定义了一个日期数据类型Date，里面包括三个int变量month, day, year对于任意两个Date变量，我们想要他们可以比较大小，就需要对这个Date的class实现Compareable接口，包括一个compareTo函数来定义如何比较大小 12345678910111213public class Date implements Comparable&lt;Date&gt; &#123; private final int month, day, year; public Date (int m, int d, int y) &#123; month = m; day = d; year = y; &#125; public int compareTo (Date anotherDay) &#123; //如果this Date &gt; anotherDay; return 1; //如果this Date &lt; anotherDay; return -1; //如果this Date = anotherDay; return 0; //需要具体实现以上比较规则 &#125;&#125; 我们可以利用Comparable类定义两个通用的helper function，在将来的排序算法中能够简化代码量： less (用于判断变量v是否小于变量w) 123private static boolean less(Comparable v, Comparable w) &#123; return v.compareTo(w) &lt; 0;&#125; Exchange (假设有一个已经实现了comparable接口的数据类型的数组a，交换数组第i项和第j项的数据) 123456private static void exch(Comparable[] a, int i, int j)&#123; Comparable tmp = a[i]; a[i] = a[j]; a[j] = tmp;&#125; Note: 这里的Comparable接口和前面的Iteratable接口、Iterator接口类似，都用到了java泛型，本质上都是一个模板类，里面有一些预先定义的函数（iterator(); compareTo(); hasNext(); next();），java系统可以根据模板对实现了这些接口的数据类型调用这些函数 Selection Sort 选择排序设立一个数组的指针i从左向右移动每移动一位，遍历指针i右侧(包括i)的所有项，选择(select)其中最小的项，与当前指针i所指的项交换这样能保证指针左侧的数据已经是排好序的，当指针i遍历到最右时所有数据已排好序 代码 123456789public static void selectionSort(Comparable[] a) &#123; for (int i = 0; i &lt; a.length; i++) &#123; //移动指针 int min = i; for (int j = i+1; j &lt; N; j++) if (less(a[j], a[min])) min = j; //找出指针i右侧最小的项 exch(a, i, min); //交换最小项至当前位置 &#125;&#125; Complexity最好和最坏情况下都需要(N-1) + (N-2) + … + 1 + 0 = N^2/2次比较大小操作和N次交换操作时间复杂度为O(N^2)，空间复杂度为O(N) Insertion Sort 插入排序同样设立一个数组的指针i从左向右移动对于i指向的数据，如果他小于他左边的项，则和左边的数据交换交换之后如果还小于左边的数据则继续交换，直到不小于为止（即指针i左侧的数据全部排好序） 12345678public static void insertionSort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) //移动指针 for (int j = i; j &gt; 0; j--) //从当前位置开始往左交换 if (less(a[j], a[j-1])) exch(a, j, j-1); else break;&#125; Complexity最好情况下，数组本身已排好序，因此需要N次比较和0次交换最坏情况下，数组为倒序，需要N^2/2 次比较和N^2/2次交换（比Selection Sort慢）对于一个已经部分排好序（partially sorted）的数组，Insertion sort所需时间是线性的对于随机的数组，平均需要N^2/4 次比较和N^2/4次交换时间复杂度为O(N^2)，空间复杂度为O(N) Shell Sort 希尔排序1. h-sort本质上是Insertion sort，只是每次比较和交换时，和往左数第h个数进行比较和交换（h为1时即为Insertion sort） 2. Shell sort设定一个较大的h（h &lt; a.length），进行h-sort缩小h再进行h-sort，直到h为1经过多次h-sort使得数组部分排序，这样最后进行insertion sort所需比较和交换次数会大大降低 如何确定h序列？一般采用3x+1，即1, 4, 13, 40, 121, 364, … 代码 123456789101112131415public static void sort(Comparable[] a) &#123; //确定最大的h int h = 1 while (h &lt; N/3) h = 3*h + 1; while (h &gt;= 1) &#123; // h-sort for (int i = h; i &lt; N; i++) &#123; //指针（从h开始，因为h往左的项没办法和再左边的第h项比较） //比较和交换往左数第h项 for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j-h]); j -= h) exch(a, j, j-h); &#125; h /= 3; //缩小h，在进行h-sort，直到h为1 (Insertion sort) &#125;&#125; ComplexityWorst case: $O(N^{3/2})$Average: O(NlogN) ~$N^{1.289}$ Ref Application1：Knuth Shuffle 洗牌算法设立一个指针i，从左往右移动每移动一位，生成一个[0,i]之间的随机数r，交换第i位和第r位 1StdRandom.uniform(i + 1); //生成[0, i+1)的随机数 Ref Application2: Convex Hull 闭包算法问题描述：平面中有一堆点，找出最少的点，这些点连起来围成一个圈可以包括所有点观察：闭包上的点，总可以通过逆时针旋转得到下一个点算法: 找出一个原点p，这个点具有最小的y-coordinate 将原点p和其他点连线，连线与y轴的夹角称为polar angle，按照polar angle从小到大的顺序依次遍历除p外所有点 将第一个点放入堆栈s 如果遍历到的点和堆栈s中的顶点组成了一个逆时针旋转(ccw turn)，则将该点入栈，否则将顶点出栈再将该点入栈 最后留在栈s中的点则为闭包上的点 如何判断三个点是否呈逆时针旋转 123456public static int ccw(Point2D a, Point2D b, Point2D c) &#123; double area2 = (b.x-a.x)*(c.y-a.y) - (b.y-a.y)*(c.x-a.x); if (area2 &lt; 0) return -1; // clockwise else if (area2 &gt; 0) return +1; // counter-clockwise else return 0; // collinear&#125; Merge Sort 归并排序分治法的应用，将一个大数组分成两个小数组，分别排好序，再合并为一个排好序的大数组 Merge函数假设一个数组，左半部分和又半部分已经单独排好序，现在需要排序整个数组需要一个aux辅助数组复制a数组，lo和hi指针分别指向两个子数组的头元素，mid为第一个数组的尾元素依次复制lo和hi指针指向的aux中的元素的最小值回a数组，并相应更改lo和hi指针 12345678910111213141516171819private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi)&#123; //前置条件 assert isSorted(a, lo, mid); // precondition: a[lo..mid] sorted assert isSorted(a, mid+1, hi); // precondition: a[mid+1..hi] sorted //复制数组 for (int k = lo; k &lt;= hi; k++) aux[k] = a[k]; //归并数组 int i = lo, j = mid+1; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; //检查数组是否排好序 assert isSorted(a, lo, hi); // postcondition: a[lo..hi] sorted &#125; 补充：Java Assertion 断言机制用于debug和提示代码功能e.g. 假设函数isSorted(a, lo, hi)用来判断数组a从第lo位到第hi位的元素是否排好序，在merge sort中我们需要merge两个排好序的数组，这样我们就可以在merge前加入assert isSorted(a, lo, hi)代码，如果两个子数组没有排好序就可以提前报错，方便debug；也可以在merge后加入，用于检验我们的merge算法是否准确，同时也方便说明这段merge代码的作用(注意：assertion是默认不启动的，需要在运行时加入java -ea myProgram) MergeSort有了merge函数，现在可以很方便的递归分割数组，再用merge函数合并 1234567891011121314private static void sort(Comparable[] a, Comparable[] aux, int lo, int hi) &#123; if (hi &lt;= lo) return; //跳出递归条件（只有一个元素的时候） int mid = lo + (hi - lo) / 2; sort(a, aux, lo, mid); sort(a, aux, mid+1, hi); //当左数组的最大值小于右数组的最小值，代表整个数组已经排好序，因此不用merge以节省时间 if (!less(a[mid+1], a[mid])) return; merge(a, aux, lo, mid, hi);&#125;public static void sort(Comparable[] a) &#123; aux = new Comparable[a.length]; //在这里创建aux数组并传入merge以避免重复创建 sort(a, aux, 0, a.length - 1);&#125; Complexity时间复杂度: ~NlgN (linearithmic)；空间复杂度： ~N （需要额外Aux辅助数组） 证明1：假设D(N)为对总长度为N的数组的两个子数组进行merge所需要的比较和数组access的数量，则有:D(N) = 2D(N/2) + N (归并需要N次比较)往下递归一层，则有: D(N/2) = 2D(N/4) + N/2需要进行两次D(N/2)，因此这层所有的D(N/2)需要(N/2) * 2 = N次比较同理再往下一层，有D(N/4) = 2D(N/8) + N/4，需要进行2*2=4次D(N/4)，一共N次比较因此一直递归到底层D(2)，每层都需要N次比较由于分治法，一共有lgN层，因此时间复杂度为NlgN 证明2（数学归纳法）：Base case：D(1) = 1假设：D(N) = NlgN证明：D(2N) = 2Nlg2N 因为D(N) = 2D(N/2) + N所以D(2N) = 2D(N) + 2N= 2NlgN + 2N= 2N(lg(2N)-1) + 2N= 2Nlg2N 改进方法1：CUTOFF对于一些小数组，或者递归到一定程度数组比较小的时候，可以直接采用insertion sort以避免不必要的递归开销假设预先设定一个CUTOFF值，当数组总长度小于CUTOFF值时对整个数组采用insertion sort（相当于base case） 12345//base case if (hi &lt;= lo + CUTOFF - 1) &#123; Insertion.sort(a, lo, hi); return; &#125; 经验证当CUTOFF=7，可使MergeSort提升20%速度 改进方法2：Buttom-up Sort（自下而上的递归）从左到右，两两元素一组进行merge操作，在4个4个元素一组进行merge，一直增大直到merge元素的长度等于数组的实际长度 1234567public static void sort(Comparable[] a) &#123; int N = a.length; Comparable[] aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz *= 2) //每次扩大要合并数组长度为两倍 for (int lo = 0; lo &lt; N-sz; lo += sz+sz) //遍历，两两一组 merge(a, aux, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1)); &#125; 优点：不需要递归，但比递归法慢10% Quick Sort 快速排序和merge sort同属递归分治法，但先完成相应的部分排序操作，再往下递归缩小问题规模（和merge sort先递归到底再从下往上进行排序操作相反） 0. 预先操作：shuffle the array对数组随机洗牌，避免worst case 1StdRandom.shuffle(a); // 传入Comparable[] a 1. 基本步骤：Partition the array随机从数组中选取一项v，并将数组分为两部分，使得数组左边所有项小于v，数组右边所有项大于v（注意：这里当存在duplicate key即存在和v相等的项时，指针跳过该项并继续移动，而非交换） 123456789101112131415161718private static int partition(Comparable[] a, int lo, int hi) &#123; int i = lo, j = hi+1; //设立左右两个指针i，j，并以a[lo]为基准进行Partition分区 while (true) &#123; while (less(a[++i], a[lo])) //找出数组左边大于基准a[lo]的数，准备和右边小于a[lo]的数交换 if (i == hi) break; //如果左指针i已经移动到数组右端，则停止移动 while (less(a[lo], a[--j])) //找出数组右边小于基准a[lo]的数，准备和左边大于于a[lo]的数交换 if (j == lo) break; //如果右指针j已经移动到数组左端，则停止移动（redundant：该命令事实无效） if (i &gt;= j) break; //如果左右两指针交叉，则数组已完成分区 exch(a, i, j); //交换左右指针所指的数据 &#125; //数组分完区后，由于指针交叉，右指针j会指向左分区最后一个数，左指针i会指向右分区第一个数 //因此交换右指针j和指针lo所指向的数据，使得基准a[lo]（此时应该在a[j]的位置）的左边所有数 //小于基准，右边所有数大于基准 exch(a, lo, j); return j; //这里返回基准的位置（即分区点）&#125; 2. 递归分别对左右两分区进行再分区操作，直到分区的大小为1或0 完整代码： 123456789101112//init：对数组进行洗牌（这样分区后的子数组同样也是随机排列）public static void sort(Comparable[] a) &#123; StdRandom.shuffle(a); sort(a, 0, a.length - 1);&#125;private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; //base case，右指针小于等于左指针 int j = partition(a, lo, hi); // 先分区 sort(a, lo, j-1); //对左分区进行排序 sort(a, j+1, hi); //对右分区进行排序&#125; ComplexityTime: ~NlogN (1.39NlogN)Best case：每次分区点都为中点，同merge sort，每层递归需要N次比较，一共有lgN层，因此一共需要N*lgN = NlogNWorst case：每次分区点都为起点，则一共有N层递归，假设为第i层，则需要i次比较，因此复杂度为~0.5 N^2 (very unlikely)Average: ~1.39NlogN (随机洗牌) 所需compare的次数和Merge sort相比大于39%，但所需交换次数更小，因此速度比merge sort快但merge sort能保证在worst case下依然有~NlogN的复杂度（因为每次递归一定是对半分）而quick sort不能保证（虽然经过洗牌后worst case基本不可能发生），因此相较之下merge sort更稳定 Space: ~lgN每层递归都需要常数级别空间（指针等），一共有lgN层和Merge sort相比可以实现in-space，即不需要额外空间 改进方法1：Cut Off同merge sort，当递归到一定程度，数组比较小的时候，可以直接用insertion sort (CUTOFF ~ 10)： 123456789private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo + CUTOFF - 1) &#123; //base case Insertion.sort(a, lo, hi); return; &#125; int j = partition(a, lo, hi); // 先分区 sort(a, lo, j-1); //对左分区进行排序 sort(a, j+1, hi); //对右分区进行排序&#125; 经验证将CUTOFF设为10到20，能使Quick sort速度平均提升20% 改进方法2：Median of Sample 随机采样基准点随机抽取数组中3个点（一般取数组左右端点和中点，即lo, hi 和 lo + (hi - lo)/2），找出其中的中位数并将其设为基准点（即交换到左端点位置），这样找出的基准点能使两分区大小大致相等 12345678910private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int m = medianOf3(a, lo, lo + (hi - lo)/2, hi); //找出3个数的中位数的指针，设为基准点 swap(a, lo, m); //交换左端点和中位数 int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi);&#125; 经验证可以使Quick sort速度平均提升10% Ref: Quick Selection 快速选择即找出一个大小为N的数组中第K小的数组，e.g. K=0即最小值，K=N即最大值，K=N/2即中位数 解决方案：利用quick sort的一种变体，即对数组进行分区：(1)假设基准点的位置刚好为K，则输出基准点j的值(2)如果基准点j的位置在K左边，则对右半分区继续分区，然后循环(1)(2)(3)(3)如果基准点j的位置在K右边，则对左半分区继续分区，然后循环(1)(2)(3)重复(1)(2)(3)直到基准点刚好为K 1234567891011public static Comparable select(Comparable[] a, int k) &#123; StdRandom.shuffle(a); //对数组进行洗牌 int lo = 0, hi = a.length - 1; while (hi &gt; lo) &#123; int j = partition(a, lo, hi); //分区 if (j &lt; k) lo = j + 1; //(2) else if (j &gt; k) hi = j - 1; //(3) else return a[k]; //(1)如果基准点位置为K,则输出基准点的值 &#125; return a[k];&#125; ComplexityTime: ~N (linear time)分析：Best Case: 每次分区后，剩余的数组为原来的一半，即需要N+N/2+N/4+N/8+…+1 ~2NWorst Case: 同quick sort，需要进行N次分区，第i次分区需要N-i次比较，共$1/2N^2$ (因此需要进行洗牌避免) Ref: Three-way Partitioning假设数组中存在很多相同元素，使用原始的quick sort会导致quadratic的复杂度，(假设数组元素全部相同，则每次递归进行i次比较而不进行交换，一共N次递归，复杂度为worst case的$1/2N^2$) 因此我们需要实现另一种partition，将数组分为三个区间，将所有与基准点相同的元素一起放在数组中间分区，左边是全部小于基准点的元素，右边是全部大于基准点的元素： 小于v的元素（左区间） v, v, v, …, v （基准点区间） 大于v的元素（右区间） 除了数组的左右边界lo和hi外，还需要3个指针，其中：i指针从左端点往右移动，直到和gt指针交叉lt指针从左往右移动，为基准点区间的起点（lt指针左边的元素为左区间）gt指针从右往左移动，为基准点区间的终点（gt指针右边的元素为右区间） 从左往右，每移动i指针一位，进行以下操作(v为基准点的值)：2.1 如果a[i] &lt; v，则交换a[lt]和a[i]，并对指针i和lt加1 (把小于基准点的值移到左区间)2.2 如果a[i] &gt; v，则交换a[gt]和a[i]，并对指针gt减1 (把大于基准点的值移到右区间)2.3 如果a[i] == v，则对指针i加1 (不需要任何移动) 1234567891011121314private static void sort(Comparable[] a, int lo, int hi)&#123; if (hi &lt;= lo) return; int lt = lo, gt = hi; Comparable v = a[lo]; int i = lo; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) exch(a, lt++, i++); else if (cmp &gt; 0) exch(a, i, gt--); else i++; &#125; sort(a, lo, lt - 1); sort(a, gt + 1, hi);&#125; Ref: Java Comparator用于数组排序：Comparable接口只实现了某种数据类型唯一一种total order的比较大小方式，如果我们希望某种数据类型能够基于不同方式进行大小比较并排序，则需要实现comparator接口：e.g. 我们设计一个student的数据类型，里面有name和section两个变量。如果我们想要student类型的数据按照name变量来排序，则需要实现一个名为ByName的内部接口类： 123456//...外面是名为Student的Classprivate static class ByName implements Comparator&lt;Student&gt; &#123; public int compare(Student v, Student w) &#123; return v.name.compareTo(w.name); &#125; &#125; Comparator接口需要定义一个compare方法，用于告诉java系统如何比较两个数据的大小然后我们可以生成一个comparator实例用于排序，这里可以用预先定义的方法生成，也可以用调用函数的方法生成： 123456789//假设有一个数据类型为Student的数组a//预先定义式，可以通过Arrays.sort(a, Student.BY_NAME); 调用并对a数组排序public Comparator&lt;Student&gt; BY_NAME = new ByName();//函数式，可以通过Arrays.sort(a, a[0].getByNameComparator())；调用public Comparator&lt;Student&gt; getByNameComparator() &#123; return new ByName();&#125; 一种数据类型可以既实现Comparable接口，又可以在内部实现Comparator接口并生成Comparator实例 Ref: Stability假设一列数据有多个key，用排序算法对其某个key进行排序一个排序算法是stable的，即对当key的值相同的元素进行排序时，不影响其他key的相对顺序（即假设key1已经是排好序的，对key2进行排序，在key2相同的元素中同样也按key1排好序） 目前已知的stable算法：insertion和merge 排序算法总结 Algorithms inplace? stable? worst average best remark selection yes $N^2/2$ $N^2/2$ $N^2/2$ N exchange insertion yes yes $N^2/2$ $N^2/4$ $N$ 常用于当N比较小或数组已经部分排好序（近乎线性复杂度） shell yes $N^{1.5}$ $N^{1.3}$ N subquadratic merge yes $NlgN$ $NlgN$ $NlgN$ $NlgN$ guarantee, stable quick yes $N^2/2$ $2NlnN$ $NlgN$ $NlgN$ probabilistic guarantee，目前实践中最快的算法 3-way quick yes $N^2/2$ $2NlnN$ $N$ 改进的quick sort，适应duplicate key Heap yes $2NlgN$ $2NlgN$ $NlgN$ $NlgN$ guarantee, in-place Week 4. Priority Queue / Heap 优先队列 / 堆定义，有序的队列，即每次删除操作只删除最大或最小值 API(e.g. Max Priority Queue, 每次删除最大值) 123456789// 注意：与一般Queue相比，我们希望MaxPQ里面的元素是comparable的，以便在队内进行排序操作public class MaxPQ &lt;key extends Comparable&lt;Key&gt;&gt; &#123; MaxPQ() // create an empty priority queue MaxPQ(Key[] a) // create an priority queue with given keys void insert(key v) // return and remove the largest key boolean isEmpty() // is the priority queue empty key max() // return the largest key int size() // number of the entries in the priority queue&#125; 最简单的两种Priority Queue实现 (Unordered PQ) 每次将元素插入到队列末端，每次删除需要遍历整个Queue找出最小值–插入需要O(1), 删除需要O(N)，查找最值需要O(N) (Ordered PQ) 每次插入需要插入到合适位置使queue始终有序，删除操作只需删除队尾元素–插入需要O(N)，删除需要O(1)，查找最值需要O(1), 分为链表和数组两种实现两种都需要O(N)时间复杂度 Binary Heap1. Complete Binary Tree Binary Tree二叉树：一个节点连接两个左右子二叉树，或者节点为空的树 Complete Binary Tree完全二叉树：整个树除了底层节点外，每个节点都有两个子节点一个有N个节点的 CBT的层数为floor(lgN) 2. Binary Heap即数组形式表现的Complete Binary Tree如何将CBT存储为数组形式？ 按照层遍历(BST)完全二叉树，并依次分配一个递增的索引index（index start from 1） 按照分配的索引放入数组a的对应位置(以上称为Heap Ordering 堆排序，即父节点的index一定小于子节点的index，同一层左边的节点index小于右边的) 通过数组形式存储，我们就无须实际生成整个完全二叉树，通过数组操作实现堆操作 3. Properties index=1 (a[1]) 对应的元素为所有元素的最大值，即根节点为最大值 index为k的节点的父节点index为k/2，子节点index为2k和2k+1 （因此我们需要index从1开始） 父节点需要大于（MaxPQ）或小于（MinPQ）其子节点 通过性质2我们可以很方便的通过数组访问CBT的节点 4. Eliminate the Violatione.g. (以MaxPQ为例，即堆元素从上往下减小) Case 1: Promotion前提假设：我们改变一个节点的值，使其大于父节点的值方法：我们可以将其与父节点交换，交换后再将该节点与新的父节点相比较，层层向上交换直到根节点(Peter Principle: node promoted to level of incompetence，类似于升职过程) 123456private void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k/2, k)) &#123; exch(k, k/2); k = k/2; &#125;&#125; Case 2: Demotion前提假设：我们改变一个节点的值，使其小于其两个子节点方法：我们将该节点与它最大的子节点交换，交换后再将该节点与新的子节点相比较，层层向下交换直到叶子节点(Power Struggle: Better subordinate promote，类似于降职过程) 123456789private void sink(int k) &#123; while (2*k &lt;= N) &#123; int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; // find the maximum child node if (!less(k, j)) break; // legal position exch(k, j); k = j; &#125;&#125; 5. Insert基于4的Promotion原理，对于新插入的元素，我们可以将其直接插入到数组尾端（即树的叶子节点），然后判断这个新插入的节点是否violation 1234public void insert(Key x) &#123; pq[++N] = x; swim(N);&#125; 该操作复杂度为logN，即我们只需要最多1 + floor(lgN)次compare 6. Delete the Max基于5的Demotion原理，我们用数组中最后一个元素（即最小值）替换掉堆顶元素（即根节点最大值），然后对新的堆顶元素做Demotion操作 1234567public Key delMax() &#123; Key max = pq[1]; exch(1, N--); pq[N+1] = null; // prevent loitering 记得把最后一个节点设为null sink(1); return max;&#125; 该操作复杂度为logN 7. Total Complexity: O(lgN)Insert: O(lgN); Delete: O(lgN); Max: O(1) 8. Other Notice 我们不希望client能够随意改动已经放入PQ的Key，因此实现特定数据结构Key时需要 a. 对整个class声明final，即public final class Key{} b.对数据结构内部所有变量需要设置为private final c. 这个数据类型中所有可调用的方法都不能改变内部变量的值(Some Immutable Variable: String, Integer, Double;Some Mutable Variable: StringBuilder, Stack, Counter, Java array) HeapSort 堆排序即利用堆顶元素最大的原理，将待排序的元素建立一个堆，每次提取堆顶元素再建立新堆，直到所有元素都提取完成 Implementation假设存在一个数组a[N]需要排序 我们将a[N]按照heap order排序，即用这些数据建立一个max heap最大堆 当我们获得堆后，堆顶元素即为最大值，将其与数组最后一个元素（即第N个元素）交换。设置一个指针i=N指向第N个元素，表示这个元素以及之后的元素是排好序的，剩余堆为[1, i-1]。对堆顶元素进行sink操作直到整个剩余堆[1,i-1]是valid的， 重复操作2，每次将堆顶元素放入已排好序区间的开头位置，同时移动指针i–，使得这个数组的前面一部分[1, i-1]是堆，后面一部分[i, N]是部分排好序的数组 注意：为了实现in-place，我们直接在原数组上建堆，即我们从后往前，对每个节点进行sink操作以确保局部堆的合法性。即我们确保了两个局部堆是valid的，然后通过sink两个堆的父节点来确保这两个堆合并为一个大堆后是valid的（实际上第N/2 + 1到第N个元素都是没有子节点的，我们可以直接从第N/2个元素开始）为什么不从前往后建堆：因为所有的insert或者sink操作，前提是需要这个堆除了这个元素外其他都是in heap order的，否则通过sink操作并不能得到valid的堆；从后往前建堆以保证每个子堆vaild以及merge后也是valid的 12345678public static void sort(Comparable[] a) &#123; int N = a.length; for (int k = N/2; k &gt;= 1; k--) sink(a, k, N); // Step 1：in-place heap builder while (N &gt; 1) &#123; // Step 2: put the largest element to the right and rebuild the heap exch(a, 1, N); sink(a, 1, --N); &#125;&#125; （注意这里我们的数组index是从0开始到N-1，而使用PQ的index是从1到N，因此我们需要在进行exch和sink操作时将两种索引进行对应的转换） Complexity: ~NlogN唯一能保证worst case为NlogN的in-place算法（Mergesort：non in-place；Quick Sort：worst case ~N^2） 补充：为什么在industry中不常用HeapSort： 其他sort访问元素都是比较连续的局部顺序访问，而HeapSort经常会需要访问数组中两个距离较远的元素（比如访问子节点依次需要访问1，2，4，8，…等相距的节点），使得CPU需要较大缓存cache（CPU缓存可能一次只能从内存中读取小部分数组，访问其他块的元素需要多次内存&lt;-&gt;缓存操作），导致效率变低 HeapSort需要的交换次数多于Quick Sort，因为每次建堆过程(insert / delete)都会打乱Heap Order，以致数据有序度降低 不是Stable的算法 （区别Merge Sort） Week 5. Symbol Table 符号表符号表主要目的就是将一个键（Key）和一个值（value）关联起来，可以将一个键值对（Key-Value Pair）插入到符号表中并能够通过key直接找到对应的value API12345678910public class ST&lt;Key, Value&gt; &#123; ST(); // 创建一个符号表 void put(Key key, Value val); // 存储键值对 Value get(Key key); // 获得key对应的value void delete(Key key); // 删去key及对应的value boolean contains(Key key); // 判断ST是否包括key boolean isEmpty(); // 判断ST是否为空 int size(); // 获取ST中的键值对数量 Iterable&lt;Key&gt; keys(); // 遍历表中的所有key&#125; Limitation关于null值的几个限定： value不能为null 当key不存在时，get(key) 方法返回null 当key存在时，put(key, value)方法将覆盖旧的value 补充：contains和delete方法的实现1234567// 对于所有的ST，contains方法都是相同的public boolean contains(Key key)&#123;return get(key) != null; &#125;// 一种简单的delete方法（仅对某些实现有效）public void delete(Key key)&#123;put(key, null); &#125; 补充：Java Equality Test (相等性测试)所有的java class内部都包含equals()函数，用于测试两个对象是否相等判断对象相等的标准： Reflexive 自反性：x.equals(x) == true Symmetric 对称性：x.equals(y) iff y.equals(x) Transitive 传递性：x.equals(y) &amp; y.equals(z) =&gt; x.equals(z) Non-null 非空：x.equals(null) == false equals实现方法： Java默认实现：x == y （即判断两个对象的地址是否相同，较不常用） 自定义(即根据不同对象类型自行设计各种判断来实现equals函数，注意需要满足上述四大标准)e.g. 假设我们有个Date类，里面有(int month, int day, int year)三个值，需要实现equals函数 123456789101112131415161718192021222324public boolean equals(Object y) &#123; // 注意这里，java规范规定传入类型必须为Object而非自定义的类 if (y == this) return true; // 优化：如果两个对象地址相同，则一定相等 if (y == null) return false; // 判断Non-null非空（标准4） if (y.getClass() != this.getClass()) return false; // 两个对象的类相同，两个对象才相同 Date that = (Date) y; // 经过上面判断后，cast操作一定成功 // 上面的代码对任何equals函数都是必要的 // 比较各个field的逻辑 if (this.day != that.day ) return false; if (this.month != that.month) return false; if (this.year != that.year ) return false; return true; // 对于字段field的比较方法（上面的day，month和year） // 1. 如果field为基本数据类型primitive type，则直接用==比较 // 2. 如果field为object类型，则用该object的equals函数进行比较 // 3. 如果field为数组，则我们需要遍历数组并对数组中的每一项进行equals比较 // (可以采用Arrays.equals(a, b)或者Arrays.deepEquals(a, b) （适用于多维或嵌套数组）， // 但不能采用a.equals(b))&#125; 两种简单的ST实现1. 无序链表键值对为链表的一个节点search：从头至尾遍历链表，直到找到对应的key =&gt; O(n)insert：每次插入先serach对应的key是否存在于链表中，如果不存在则直接插入到链表头部 =&gt; O(n)注意:这种实现只需通过equals()函数比较key而无需通过compareTo()进行key排序，但也无法顺序输出键值对 2. 顺序数组 + 二分查找需要两个并行数组keys和values来分开存储key和valuesearch：通过二分查找函数rank()来获取key在keys数组中的索引i，并以此索引i来获得value = values[i]，如果未找到对应的key则返回null =&gt; O(logN)insert：通过rank()函数找到对应插入的位置i，对keys和values数组将i后面的所有元素往后移动一位，再将key-value插入到对应位置；如果key存在则直接改写对应的value值 =&gt; O(N)注意：和无序链表实现相比，需要通过compareTo()函数实现二分查找，同时可以顺序输出键值对 补充：当key是comparable时，还可以有其他应用（统称为ordered operations）： 找到最小或最大的key （min()和max()函数）或者删除最大或最小值(deleteMin()和deleteMax()函数) 查找特定位置的key(select()函数) 找到最接近的key(ceiling()和flooring()函数) 获得key在ST表中的顺位(rank()函数) 迭代ST表 Binary Search Tree 二叉查找树定义每个节点有一个key值，每个节点的key值大于这个节点的左子树中所有节点的key值，小于这个节点右子树中所有节点的key值 每个node有四个field：key，value，left，right 123456789private class Node &#123; private Key key; private Value val; private Node left, right; public Node(Key key, Value val) &#123; this.key = key; this.val = val; &#125;&#125; 特征与quick sort的关联：和quick sort一样有一个partition的过程，因此BST的inorder是有序的 查找key对应的value12345678910public Value get(Key key) &#123; Node x = root; while (x != null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else if (cmp == 0) return x.val; &#125; return null;&#125; 复杂度：key所在的节点深度+1（Average: ~2lnN，由quick sort启发得来） 插入一个key-value pair1234567891011public void put(Key key, Value val)&#123; root = put(root, key, val); // re-link &#125;private Node put(Node x, Key key, Value val) &#123; if (x == null) return new Node(key, val); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left, key, val); else if (cmp &gt; 0) x.right = put(x.right, key, val); else if (cmp == 0) x.val = val; return x; // tricky part：注意这里我们虽然返回的是一个节点，但我们需要把他想象成一个link，让其父节点连接到这个修改后的子树&#125; 复杂度：key所在的节点深度+1 （Average: ~2lnN）补充：二叉树的形状，取决于节点插入的顺序如果二叉树的节点是按顺序插入的，则二叉树呈一斜线，此时二叉树的高度最大 (worst case)，等同于一个linkedlistAverage Height: ~4.311lnN (随机顺序插入情况下) 删除一个key-value pair1234567891011121314151617181920public void delete(Key key)&#123; root = delete(root, key); &#125;private Node delete(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left, key); else if (cmp &gt; 0) x.right = delete(x.right, key); else &#123; // 找到要删除的节点 if (x.right == null) return x.left; // 没有左子树，直接返回右子树 if (x.left == null) return x.right; // 没有右子树，直接返回左子树 // 找出右子树的最小节点来替换该节点 Node t = x; x = min(t.right); // 找出右子树的最小节点替换该节点 x.right = deleteMin(t.right); // 删掉这个最小节点（因为要替换到该节点的位置） x.left = t.left; // 将旧节点的左子树附到新节点的左子树上 &#125; x.count = size(x.left) + size(x.right) + 1; // 更新该节点的size() return x;&#125; 复杂度：sqrt(N)这种删除方法存在一个问题，因为我们总是将右子树的最小值替换到删除的节点，因此当长时间进行动态的insert和delete操作后，树变得不再balance而会偏向一边（左边），导致后面的insert、search和delete操作的复杂度变为比lgN更大的sqrt(N)该问题目前无解，即使是随机的选取左子树的最大值或者右子树的最小值替换删除的节点，复杂度仍为sqrt(N)另外如果delete操作是order的，也会导致BST变为完全不平衡的树（因此引入红黑树解决此问题，后续会讲） Ordered Operationsmin() / max(): 一直递归左子树直到叶节点即为最小值；一直递归右子树直到叶节点即为最大值floor()：找出比该key小的所有节点的最大值 123456789101112131415public Key floor(Key key) &#123; Node x = floor(root, key); if (x == null) return null; return x.key;&#125;private Node floor(Node x, Key key) &#123; if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x; // 找到exact same的值，直接返回节点 if (cmp &lt; 0) return floor(x.left, key); //当前节点比key大，说明target肯定在该节点的左子树中 Node t = floor(x.right, key); if (t != null) return t; // 当前节点比key小，说明当前节点可能是target // 如果在他右子树中能发现target，则证明能找到更大的比key小的值，返回新的target // 否则当前节点的值就是要找的下界，直接返回 else return x;&#125; ceiling()同理类推size()：在node节点中增加一个size field，代表该节点为根的树的大小，在插入操作时同时修改每个节点的sizerank()：利用size()函数递归操作，对于某个节点的rank，等于其左子树的size()以及其父节点的左子树的size()依次递归 Ordered Iteration 123456789101112public Iterable&lt;Key&gt; keys() &#123; Queue&lt;Key&gt; q = new Queue&lt;Key&gt;(); inorder(root, q); return q;&#125;// Inorder traversal: BST的中序遍历为有序的private void inorder(Node x, Queue&lt;Key&gt; q)&#123; if (x == null) return; inorder(x.left, q); q.enqueue(x.key); inorder(x.right, q);&#125; 复杂度：除了Ordered Iteration为N，其他ordered operation的复杂度都为h (节点的深度，avg为lgN) 2-3 Tree定义&amp;特征2-3 Tree是Balanced Search Tree的一种，每个节点可以有1个或两个key，分别称为2-node或3-node:2-node: 包含1个key和2个子节点，其中左子树的所有节点的key小于该节点，右子树所有节点的key大于该节点3-node: 包含2个key和3个子节点，假设该节点有两个key，分别为a和b，则有： 这个节点左子树的所有节点的key小于a 这个节点右子树的所有节点的key大于b 这个节点中子树的所有节点介于a和b之间 2-3树有如下特征： 每条从root节点到叶子节点（或null节点）路径的长度总是相等的（即Perfect Balanced） 2-3树的中序遍历也是有序的 树的高度： worst case（即全为2-node）：lgN best case（即全为3-node）：log_3 N (~0.631lgN) Search基本方法和BST相同： 如果target在一个2-node或3-node里面，表示找到target 如果dfs到一个2-node且target不在里面，如果2-node的key &gt; target则递归到左子树，反之递归到右子树 如果dfs到一个3-node且target不再里面，假设有两个key分别为a，b，如果target &lt; a则递归到左子树，如果a &lt; target &lt; b则递归到中子树，如果target &gt; b则递归到右子树 如果节点为null，代表没找到target，返回null Insert假设我们通过search找到key要插入的位置，为一个2-node或3-node叶子节点 假设要插入的位置为2-node，我们可以直接插入到2-node使其变为一个3-node 如果要插入的位置为3-node： 我们先将key插入到这个3-node使其变为一个临时的4-node（即含有三个key和四个子树） 然后进行split操作：将这个4-node分开成3个2-node，最左边的2-node包含了原本4-node的左边两个子树，最右边的2-node包含了原本右4-node的右边两个子树，中间的2-node将其向上合并到原本4-node的父节点 此时原本4-node的父节点可能是一个3-node，也有可能是一个4-node，如果是一个4-node，就继续进行split操作并向上合并。如果是3-node则无需进一步操作 补充：2-3树原理较为简单，但实现比较复杂，需要考虑到多种情况，这里暂时不需要掌握具体实现另外有其他实现更简单的Balance Search Tree（e.g. 红黑树） Complexity所有操作都能保证为lgN的复杂度 (lgN guarantee) (left-leaning) Red-Black BSTs定义&amp;特征基本思想：2-3树因为存在2-node和3-node（尤其是3-node），因此插入和查找操作相对BST比较复杂。我们希望我们的树结构能和BST一样简单,但是又能体现出2-node和3-node。即我们需要在BST中用一种简单的方法来表现3-node 如何在BST中表现3-node？ 我们用一个称为left-leaning link（即上图红色的边）来粘结3-node，此时原本3-node的左子树为a的左子树，中子树为a的右子树，右子树为b的右子树 原本3-node中较大的key为新的BST中的根节点，我们用红色的边标记a和b之间的internal link，以示和其他link区别 e.g. 完整的2-3 Tree以及其对应的RB Tree表示 2-3 Tree.png 黑色的边连接原本的2-node或3-node，红色的边为internal link，用来表现3-node 红黑树定义： 任何节点不会有两个红色的边与其相连 任何从根节点到叶子节点（或null节点）的路径所包括的黑色的边的数量相同 （黑色边连接2-node和3-node，原先2-3树中每条路径的节点数相同，对应红黑树的黑边数量相同） 所有红色的边都是向左的，称为left-leaning Search &amp; other ordered opsSearch操作以及其他ordered ops和BST是完全一样的，但由于树的平衡性更好，因而效率更高 Implementation1234567891011121314private static final boolean RED = true;private static final boolean BLACK = false;private class Node &#123; Key key; Value val; Node left, right; boolean color; // color of parent link&#125;private boolean isRed(Node x) &#123; if (x == null) return false; return x.color == RED; &#125; 在BST节点的基础上增加一个color field，用来表示这个节点连接到其父节点的边颜色 （上图中，A, E, S节点的color为RED而其他node为BLACK） 补充：我们默认所有null节点都是黑色的（因为它不可能是3-node中的key） Basic Operations Required For Insertion在实现insertion 操作之前，我们需要实现两个基本的rotation操作，使得将一个right-leaning的3-node变成left-leaning，或者将一个left-leaning的3-node临时变成right-leaning（再变回left-leaning）。还需要一个等效于原来4-node分裂成2-node的操作。后续Insertion操作会用到这些操作 Rotate Left rotateLeft.png 假设h节点的右节点为红色（即leaning-right），rotate之后x将成为新的父节点并返回。剩余的三棵子树中，原来的左子树和右子树都不用变（还是连接在原来的h和x节点上），中子树需要从原来x节点的左子树连接到h节点的右子树 123456789private Node rotateLeft(Node h) &#123; assert isRed(h.right); Node x = h.right; // 先保存x h.right = x.left; // 将中子树从x连接到h上 x.left = h; // 旋转，将h连接到x左边（变为left-leaning） x.color = h.color; //同时需要改变两个节点的颜色 h.color = RED; return x; // 返回旋转后新的3-node根节点&#125; Rotate Right 原理同Rotate Left，先调整中子树再rotate rotateRight.png 123456789private Node rotateRight(Node h) &#123; assert isRed(h.left); Node x = h.left; h.left = x.right; x.right = h; x.color = h.color; // 注意这里，我们希望旋转之后除了这个3-node之外整个树其他部分都不变化（包括其他各边的颜色），因此这里我们新的根节点的颜色（即这个node连接到上面父节点的边的颜色）选择与原来一样保持不变 h.color = RED; return x;&#125; Color Flip colorFlip.png 在insert的过程中可能会遇到一个节点的两个子节点都是Red节点（等价于原来的4-node）。此时我们需要将其分为两个2-node（即图中的A和S节点），并将表示中间key的节点（图中的E）向上移动。 将4-node分为2个2-node，可以直接将两个红色节点设为黑色即可 对中间节点（E节点）的颜色进行分类讨论： 假设E的父节点表示的是一个2-node（即只有一个key），则直接将E设为红色节点可以使这个2-node变为一个3-node。即使我们不知道E是左节点还是右节点，我们也可以通过旋转操作进行调整 假设E的父节点表示的是一个3-node，则将E设为红色后，E的父节点将有两个红色节点，此时等价于左图中的4-node情况，需要继续进行color flip 因此我们直接将4-node的中间节点设为红色，左右节点设为黑色即可 (只需设置相应节点的颜色而无需更改link) 12345678private void flipColors(Node h) &#123; assert !isRed(h); assert isRed(h.left); assert isRed(h.right); h.color = RED; h.left.color = BLACK; h.right.color = BLACK;&#125; Insertion基本策略：通过上面的rotation和color flip，实现与2-3 Tree insertion一一对应的等价操作 按照search方法找到插入位置后，我们将要插入的节点设为红色并插入到对应位置（即将原本的2-node变为3-node或原本的3-node变为4-node，因而设为红色） 如果插入后的link是right-leaning的，我们通过left-rotation使其变为left-leaning的合法RBT 如果插入后，使得存在两个连续的边（下图两种情况） 左图情况下，直接以c为节点进行rotateRight使其变为一个4-node，再进行color Flip 右图情况下，因为a节点会比b节点优先检查到，在检查a节点时会进行第二步的left-rotate操作使其变为左图情况 （补充第另外两种种右左情况和右右情况，因为先检查是否存在right-leaning，因此进行left-rotate后都会变为上面两种情况，因此实际上不会存在） 因此任意两个node插入第三个node，最终都会归结到左图情况，进行rotateLeft再color flip即可 插入后依次向上对每个节点进行合法性检查，最终得到合法RBT 1234567891011121314private Node put(Node h, Key key, Value val) &#123; // BST插入部分（同一般BST插入） if (h == null) return new Node(key, val, RED); int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else if (cmp == 0) h.val = val; // 检查每个节点是否合法：调整节点使其成为合法RBT if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h);//此时该节点是leaning-right的，直接左旋 if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h);//上面case3, 等价于生成4-node if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); //split 4-node return h;&#125; 状态转换过程: 对每个非法节点进行一步步的状态转换（一共三种状态），直到转换为合法状态 ComplexityTree Height: &lt;= 2lgN in worst case (每条路径的黑边数相同，且没有两条连续的红边，假设worst case最坏情况是一条黑边一条红边交错相连，因而worst case为2lgN)；1.00lgN in average case； Time Complexity: 2lgN in worst case and lgN in average case for all operations. （Optional）B-TreeDefinationB-树是Blanced Search Tree在文件系统中的应用。通常我们需要存储大量文件和数据在external storage中，需要尽可能快的查找到所需的文件 基于2-3树，B-Tree一个节点设置为可以包含最多M个key（M往往很大，e.g. 1024）和M-1个link （而2-3树中每个节点只能包括1个或2个key）。B-Tree还有如下性质 root节点至少要有两个key 其他节点至少要有M/2个key （我们不希望每个节点太空，以保证查找高度不会太高） 所有的数据都存储在external node（外部节点，即叶节点）中，只存储数据的key且从左到右有序排列 B-Tree的internal node（内部节点，即非叶节点）仅用于搜索而非存储数据和key 当节点填满后，将一分为两个节点，并在其父节点添加一个新key BTree.png Complexitylog_{M-1} N 到 log{M/2} N，for all operations （每个节点包含的边的数量总是在 M/2 到 M-1之间） Avg：当M = 1024 &amp; N = 62 billion, log {M/2} N &lt;= 4，即探查次数不超过4次 Geometric Application1D Range Search在ST的基础上增加两个函数： Range Search：找出所有大小介于k1和k2之间的key Range Count：找出所有大小介于k1和k2之间的key的数量 如果将所有key排列成一条直线（即1维状况），上面两个操作等同于找出这题直线某个区间内的所有点 BST Implementation： count：使用rank函数，找出两个key的rank，两者之差的绝对值即为结果 search：中序递归，先递归查找左子树中是否包含在两个key之间的key，再检查当前key，再递归查找右子树是否包含在两个key之间的key Time Complexity: data structure Insert range count range search unordered list 1 N N ordered array N logN R + logN BST logN logN R + logN N = number of keys R = number of keys that match 1D Range Search的应用: Orthogonal line segment intersection Orthogonal line segment intersection.png 如图，平面中有许多水平线和垂直线。我们需要找出所有的交点。不存在任何重合的直线。 方法 （Sweep-line Algorithm，线段扫描算法）： 图中红色的线从左到右依次扫描。遇到一条水平线的左端点后，将这条线的y坐标插入到BST中 （图中按0，1，2，3顺序依次插入） 遇到一条垂直线的右端点，则将该线的y坐标从BST中移出（移出2） 遇到垂直线后，假设这个垂直线两端点的y坐标分别为y1和y2，对BST进行Range Search(y1, y2)可以找到与该垂线相交的直线数量（e.g. 搜索线段4在BST中的range可以得到1的y坐标在range范围内，即与线段4相交的线段数量为1） 时间复杂度：NlogN （每条线需要logN复杂度的BST操作，一共N条线） KD Range Search即我们假设每个key有K个维度，通过KD-Tree我们可以搜索给定维度范围内的key e.g. 假设二维空间内有一群数据点，每个数据点包括两个field，如一个人的收入和年龄。我们可以通过一个2-D正交搜索（2-D Orthonogal Range Search）来查找给定收入和年龄范围内（e.g. 100K &lt; income &lt; 200K, 25 &lt; age &lt; 40）的所有数据点（等价于查找二维平面内用一个长方形框住的所有点） Grid ImplementationSteps 将二维空间分为M*M个网格 将每个网格中的点分别存储到对应的list中 用一个2-D数组来索引每个网格的list 对于插入操作，利用索引将点直接插入到对应的网格的点list中 对于range search操作，对于给出的2-d range query，我们找到在这个范围内的所有square，提取出对应square的所有点，再一一检查每个点是否在给定的2-d range query范围内 Complexity Space：M^2 + N (M^2个索引，以及需要用M^2个list存储所有N个点) Time：对于每个examined的网格需要平均N/M^2次检查（平均每个网格包含N/M^2个点） 因此对于划分的网格大小M如果过大会导致空间复杂度上升，过小会导致时间复杂度上升（即space-time tradeoff）。 一般我们选择M = sqrt(N)，如果数据是evenly distributed的，则初始化索引的复杂度为N（sqrt(N) ^ 2）；insert的复杂度为1，range search的复杂度为1（每个网格平均包含一个点） Issue 通常情况下，数据往往不是evenly distributed而是clustering（即大部分数据都集中在某一片区域，见上图右），导致存在少数很长的list和大多数很空的list（range search复杂度增大至趋近于N），因此需要其他数据结构 2-D TreeExample 2-DTree.png 每个点表示为一个key，包含一个二维坐标。 我们将数据点依次插入到一个二叉搜索树中： 对于树中奇数层的点，其左子树的点为平面中在该点左边的点，其右子树中点为平面中在该点右边的点 （e.g. 以点1为例，左子树中3，4，5，6都在点1的左边，2，7，8，9，10都在点1的右边，相当于以点1为基准将平面分为左右两部分） 对于树中偶数层的点，其左子树的点为平面中在该点下边的点，其右子树中点为平面中在该点上边的点 （e.g. 以点3为例，左子树中4，5都在点1的左边，6在点1的右边，相当于以点3为基准将子平面分为上下两部分） 这样我们每插入一个点，就将一个平面分为两个更小的平面 Range Search in 2-D Tree e.g. 假设我们需要搜索上图中绿色框范围内的点 从根节点开始，判断节点是否在范围内，如果在则添加到结果集 对于在奇数层的节点，如果查询范围的左边界在该节点左边，则递归查找到左子树，如果查询范围的右边界在该节点右边，则递归查找到右子树 对于在偶数层的节点，如果查询范围的上边界在该节点下边，则递归查找到左子树，如果查询范围的下边界在该节点上边，则递归查找到右子树 Complexity：R + logN 2-D树的补充应用：Find Nearest Neighbor 给出一个点，找出现存平面中离该点最近的点 KDNearestNeighbor.png 从根节点开始，计算该节点与目标节点的距离，并更新最短距离 目标节点应该在该节点划分的两个区域的任意一边，我们优先递归到包含目标节点的区域对应的子树（e.g. 图中目标节点在1节点的左边，因此我们先递归到左子树，即3节点） 递归完包含目标节点的一边后，我们再判断是否需要递归另外一边的子树（e.g. 递归完1节点左半部分后，得到最近的neighbor为节点5，此时当前最短距离小于1节点右边的理论最短距离（即红色虚线的长度），因此1节点右边的节点与目标节点的距离不可能小于当前的最短距离，因此我们不需要再递归右节点部分，相当于剪枝） Complexity：logN（in average），N（worst case, even if tree is balanced） KD Tree 类似于2D-Tree，奇数层的节点将平面分为左右两部分而偶数层的节点将平面分为上下两部分，我们同样利用BST将其延伸到k维。 假设节点P在第i mod k 层，则P的左子树的点在第i维都比点p小，右子树的点在第i维都比p大 Interval Search Tree1D Interval Search Problem 我们希望实现一种数据结构，能够保存一系列区间（interval），这些区间有可能存在重叠（overlap） 这个数据结构能够完成如下操作： insert：插入一个interval (lo, hi) search：搜索一个interval (lo, hi) delete：删除一个interval (lo, hi) interval intersection query：给定一个interval (lo, hi)，找出所有和这个interval交错（intersect）的区间 （我们假设所有interval的起点都不同） Implementation 利用BST，每个节点存储一个interval，但只用interval的左端点（即lo值）作为BST每个节点的key。 另外每个node还要存储以该node为根节点的树中所有节点最大的右端点，记为max （图中蓝色部分） Insertion 插入操作等同于一般BST的插入，以interval的左端点为key查找到对应的插入位置。 插入到对应位置后，要延搜索路径回溯并更新路径节点上的max值 Interval Intersection Search 假设给出一个query interval (lo, hi)，只需要查找到一个与其交错的interval 从根节点开始，对每个节点表示的interval if 该interval和query interval交错，则将其添加到结果集 else if 该节点的左子树为空，递归到右子树 else if 左节点的max值小于query interval的lo值，递归到右子树 （即所有左子树中的节点都在query interval的左边，不可能存在交叉） else 递归到左子树 12345678Node x = root;while (x != null) &#123; if (x.interval.intersects(lo, hi)) return x.interval; else if (x.left == null) x = x.right; else if (x.left.max &lt; lo) x = x.right; else x = x.left;&#125;return null; 有效性证明： 当我们搜索右节点时，代表左子树中不可能存在任何交错的节点区间 如果我们搜索左节点，如果在左子树中找不到交错的区间，代表即使我们搜索右子树也不可能找到交错的区间节点 证明：假设左子树不存在交错节点，同时因为搜索左子树，代表左节点的max值大于或等于query interval的lo值（即左子树中存在右端点大于lo的区间）。 因此如果在左子树中找不到交错节点，代表左子树中所有区间的最左端点都在query interval的右边（即图中hi &lt; c）。又因为右子树中所有区间的左端点肯定大于左子树的最左端点，因此右子树中也不可能找到交错节点 延伸：如何找出所有与其交错的intervals 按上面找一个intersection的方法，每找到一个交错interval，将其删除（或标记为已找到并不再访问），直到找到所有的interval Complexity：我们可以采用红黑树，使得对insert, delete, search和find one intersect interval操作的复杂度为logN，对find all intersect interval，假设最后结果集的大小为R，则复杂度为RlogN（即需要R次find one intersect interval操作） Application：Orthogonal rectangle intersection 平面内有一系列长方形（有可能存在相互覆盖或交错），找出所有交错的长方形 RectIntersectSearch.png 算法：Sweep Line Algorithm 线性扫描法（类似于1-D range search） 从左到右扫描所有长方形，每个长方形有一个y-interval记录长方形的上下两边的y值区间。我们用一个Interval Search Tree存储长方形的y-interval 扫描到一个长方形左边时： 查找Interval Search Tree中与该长方形y-interval交错的长方形，并记录到结果集 将这个长方形的y-interval插入到Interval Search Tree中 扫描到一个长方形右边时：将这个长方形的y-interval从Interval Search Tree中移出 复杂度：NlogN + RlogN 将所有长方形按x值排序以便扫描（NlogN） 所有长方形的y-interval插入到Interval Search Tree中（NlogN） 删除Interval Search Tree中的y-interval（NlogN） 搜索交错的区间（NlogN + RlogN） 该问题为原本2D Orthogonal line segment intersection的升级版，即2D orthogonal rectangle intersection。该算法将原本问题降维至1D interval search，因而降低了时间复杂度 BST几何应用总结 BSTGeometricAppConclusion.png Week 6. HashTable 哈希表哈希表本质是一个Space-Time Trade-Off的数据结构，相比其他Symbol Table实现（如BST，红黑树），插入和查找的速度更快，但不支持ordered operations 我们将key-value键值对存储在一个数组中，并实现一个hash function以获得某个key在数组中的index 为此我们需要解决以下问题： 如何设计hash function 如何判断两个key是否相等（Equality Test） 如何解决两个不同的key具有相同的hash值（Collision Resolution） Hash Function 哈希函数我们希望Hash Function计算效率要高，且每个计算出的index出现的可能性尽可能相等（e.g. 假设key1-10十个数，key1-9的hash都为0而key10的hash为1，这样会造成大量的hash冲突） hashCode()对于一个任意类型的对象，我们使用hashCode()函数将其简化为一串数字（介于Integer.MIN_VALUE和Integer.MAX_VALUE之间），便于之后我们设计的hash函数通用化。hashCode()函数需要满足以下要求： 两个相等对象的hashCode相同，即当x.equals(y) == true时, x.hashCode() == y.hashCode() 尽可能满足（不一定）当两个对象不同时，其hashCode也不同。即x.equals(y) == false时x.hashCode() != y.hashCode()。 因此hashCode()函数如果只返回一个常数(e.g. 17)是满足要求的，但没有什么实际用途。 标准方法（Horner’s method）：31x+y 我们先设置一个初始hash值为17（一个质数），然后对于自定义数据结构中的每一个field，我们都采用hash = 31 * hash + field.hashCode()来计算： 如果field为原始数据类型，则将其转化为包装类型（wrapper type）再使用其hashCode()函数 如果field为包装类型或引用类型，则直接采用其hashCode()函数 如果field是一个数组，则对其中的每一项采用hashCode()函数和31x+y规则（或者直接使用Arrays.deepHashCode()函数）。 补充：所有java的class都内置了hashCode()函数。默认情况下，hashCode()为对象的地址。包装数据类型有其设计好的hashCode()函数 hash()假设我们可以使用的数组空间大小为M，则我们的hash()函数为： 12private int hash(Key key)&#123; return (key.hashCode() &amp; 0x7fffffff) % M; &#125; // 注意 注意：因为key可能存在负数，因此我们需要先转成正数后才能进行取模操作。 另外我们不能直接用Math.abs()取正数，因为当hashcode为Integer.MIN_VALUE时该操作会导致整数溢出 Uniform Hashing Assumption假设数组空间大小为M，且每个key获得0~M-1的index的概率都是相同的 从概率论角度，当我们随机插入~ sqrt(πM / 2)个key后，会出现两个key有相同的index 当随机插入~ MlnM个key后，数组每项都会存在至少一个key 当随机插入M个key后，数组中包含最多key的项大概包含log M / log log M个key Collision Resolution 冲突解决即使我们采用了均匀分布的hash函数，仍然可能存在不同的key具有相同的hash值，即hash冲突 Separate Chaining 链表法假设我们的index数组大小为M &lt; N（待插入的键值对数量）。我们对数组中每一项放入一个链表，对于相同hash值的key所对应的键值对将插入到对应的同一个链表。 Hash：先用hash函数计算key在表中的index i （0 &lt;= i &lt;= M-1） Search: 找出数组中的第i项，对其链表进行线性查找 Insert：如果key不存在则将键值对插入到对应的链表头部。如果存在则改变对应的value值 平均情况下，每个链表的长度为N/M，因此Search和Insert的复杂度也为~N/M M的选择不能过大和过小，一般我们希望平均链表长度为5，此时M ~ N/5，复杂度趋近于log 1 Opening Addressing 开放地址法又称为linear probing线性探测法 Insert：仍然使用hash()函数获取key-value在表中的index，当这个index在数组中已被占用时，从这个index开始向后遍历（index + 1, index + 2, …），直到找到一个空的index将键值对插入 （注意这里index遍历是循环的，即当index遍历到数组最后一位后，回到数组开头） Search：获得index后查找对应位置是否存在key，如果key不相同则继续向后遍历，直到遇到空位置 注意：index数组的大小M &gt;= N，以保证所有数据都能够被插入 Complexity 当数组是半满的情况，每次插入或查找需要的平均探测次数（即依次遍历找到空位的次数）为~3/2 当数组是接近全满后，每次插入或查找的平均探测次数为~ sqrt(πM / 8) 即数组越满，插入和查找的效率越低 HashTable 和 Balanced BST对比 HashTable Balanced BST （R-B BST） 代码更为简单 性能更稳定 对于较为简单的key而言效率更高 支持Ordered Operations HashMap TreeMap，TreeSet 几种ST实现比较 STcomparasion.png","categories":[{"name":"Note","slug":"Note","permalink":"http://blog.david916.com/categories/Note/"}],"tags":[{"name":"Note","slug":"Note","permalink":"http://blog.david916.com/tags/Note/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://blog.david916.com/tags/Algorithm/"}]},{"title":"GPU Accelerated Similarity Self-join","slug":"GPU Accelerated Similarity Self-join","date":"2019-12-20T11:49:08.321Z","updated":"2020-07-20T15:10:05.722Z","comments":true,"path":"2019/12/20/GPU Accelerated Similarity Self-join/","link":"","permalink":"http://blog.david916.com/2019/12/20/GPU Accelerated Similarity Self-join/","excerpt":"","text":"IntroductionThe similarity self-join is an operation that finds all objects in a dataset within a distance threshold of each other. A typical method for the self-join is to utilize the search-and-refine strategy: search a set of candidate points that may be within the search radius for every query point, and then refine them by performing the distance calculations. Numerous searches for points within the search distance take advantage of the GPU’s high memory bandwidth and massive parallelism. Thus, the GPU’s architecture is suitable for massively parallel range queries and join operations. OptimizationThere are many ways for points indexing, divided into two categories: Tree-based indexes (such as R-trees, quad-trees and kd-trees), and non-hierarchical indexes (such as Grids, see Figure 1). Due to the GPU’s SIMT architecture, tree indexes cause divergence in workload among the groups of threads in GPU call warp, so the total performance is depend on the threads in a warp that needs the longest time. On the other hands, each thread performs similar execution pathways in Grid structure. However, we may still have various number of points in different cells in a grid, which is also not very efficient in SIMT architecture. Figure 1 (Figure 1: An example of grid indexing structure in 2D. We want to find all the points that are within ε with point p (the point in the circle area). In order to do that, we use the grid index structure so every point are within a grid cell. Then we search all the points in the cells adjacents to the cell that contains p (nine cells in the large square bounded by the dash line) to limit the search area. After we find all the points, we verify each point by performing distance calculations (in here we use Euclidean metric), to see if the point are within the circle) Our goal is to minimize the divergence of workload among each threads. To achieve that, we utilize the grid structure, improve it and develop another two grid-base indexing methods. We also extract the feature of datasets to determin which grid indexes we should use, in order to maximize the performance. We have run experiments on differents datasets, synthetic or real-world, and our method generally has better performance, with up to 20x speedup compare to a CPU implementation and up to 5.5x speedup compare to another state-of-art GPU implementation (See Figure 2). Figure 2 (Figure 2: (a) compared with another CPU self-join implementation call SuperEgo and (b) compare to another GPU self-join implementation call GPUCalcGlobal. Datasets are from 2D to 8D. The red lines show the average speedup 6.0x and 2.0x, and the black dash line shows where our approach achieves a speedup (or slowdown)). We are currently improving our optimization methods and drafting the related outcomes. To be continued …","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Research","slug":"Research","permalink":"http://blog.david916.com/tags/Research/"},{"name":"GPU","slug":"GPU","permalink":"http://blog.david916.com/tags/GPU/"},{"name":"Parallel Computing","slug":"Parallel-Computing","permalink":"http://blog.david916.com/tags/Parallel-Computing/"}]},{"title":"Prototype Time Limited Dispatch (TLD) Application","slug":"Prototype Time Limited Dispatch (TLD) Application","date":"2019-03-03T19:04:00.000Z","updated":"2020-07-21T04:50:09.615Z","comments":true,"path":"2019/03/04/Prototype Time Limited Dispatch (TLD) Application/","link":"","permalink":"http://blog.david916.com/2019/03/04/Prototype Time Limited Dispatch (TLD) Application/","excerpt":"","text":"For more details, visits the project website &amp; Github Repo Updatesv2.1 (03/04/2019) Updated chart view: now you can choose the data you want to make a chart for it v2.0 (02/26/2019) New GUI design Add menu for multiple planes data access Two view modes: the table view and the chart view Real-time data updating and parsing Rawdata file can be download directly v1.1 (12/08/2018) Bug Fix: Fix the csrf verification issue when user click on the return key. v1.0 (12/07/2018) Release for tech demo Finished the implementation of Django, include the user authencation, database connection and data integrity verification by hash value Description Honeywell Aerospace is a leading manufacturer of all sorts of aircraft engines ranging from helicopters to commercial airliners. These engines and their connected systems generate data every flight that is important for the functionality of their product. While in flight, an engine is constantly reading sensor data and storing it on the onboard computer called the Engine Control Unit (ECU). Currently, to gather this data, a technician will physically download the data from the ECU through a wire connection. The cumbersome process of physically connecting to a computer and downloading this data on location greatly limits the amount of flight data to collect. Our team, TLD Worker Bee, are working on the project Prototype Time Limited Dispatch (TLD) Application for our sponsor, Harlan Mitchell from Honeywell Aerospace. The initial concept for this project was provided by our sponsor, in the form of a Capstone project proposal. Our prototype is a web app that uses an internet connection to connect to the data stored in the cloud for a completely wireless experience. It verifies data integrity before showing the user any data to avoid reading false data. This ensures the mechanic knows exactly what maintenance to perform on the engine from anywhere in the world. RequirementsFor our requirements acquisition process, we began by brainstorming different use cases for our product to see how a typical user might interact with our system. We were able to come up with a few requirements of our own, but we wanted our sponsor’s opinion on what requirements he felt our system should have as well. We spoke to our sponsor, Harlan Mitchell, about what he would like to see in our final product and how he would like the final product to perform. We explained to him our proposed solution and what we had in mind to fix his problem, and he explained how our proposed solution needs to perform. From this discussion, we gathered a handful of functional and non-functional requirements. Our functional requirements are as follows: [F-SYS1] The web viewer tool shall download the raw data file from the cloud to the user’s computer upon user’s request. [F-SYS2] The web viewer tool shall display the data stored in the database. [F-GUI1] The user shall navigate to data by plane tail number. [F-GUI2] The GUI shall be adaptive for PCs and tablets using Google Chrome. Note: Adaptive means the user will see the data without needing to side scroll. These functional requirements describe how the system is expected to function; they cover both system requirements and GUI requirements. Our non-functional or performance requirements are as follows: [P-GUI3] The web viewer tool shall display data onto the web page after receiving it from the cloud. [P-DT1] The database shall reject SQL injection 100% of the time. [P-SYS3] The web viewer tool shall explicitly validate the data after receiving it from the cloud before displaying it on the web browser. This validation will be done by comparing local and cloud MD5 hash values for the data. These non-functional requirements describe benchmark goals for the system; they cover system, GUI, and database requirements. SolutionThe solution our team has in mind to build for our sponsor is a prototype web application that will serve as a viewing tool for data that is stored in a cloud. The web application will be able to download the data files a user is requesting from the cloud and display them in the web browser of choice. The web viewing tool we build will be usable on Google Chrome and Apple Safari. We have three main components that will each serve a purpose in our solution: cloud storage, parsing and verification services, and a web application. The cloud storage contains the databases for this prototype: one to store data for processing and one to store data that is already processed. These databases communicate with each other using Python to perform operations on the pre-processed data. We will be using Amazon S3 cloud storage to hold the database containing the pre-processed data and Amazon RDS to hold the database containing the processed data. The RDS database is the one that will be accessed when a user makes a data request in the web application. Before the data reaches the web application, it will be sent through a parsing and a verification tool. These tools/services will ensure data integrity throughout the data flow process. For the web application itself, we will be using Django and Python to create a web page to display data that a user requests from the database. This flow of data can be seen below in figure 1. The data starts by being collected from the ECU and is then sent to the Amazon S3 cloud database. From there, the data is sent through a parsing tool for data processing and is then sent to the Amazon RDS database. Once the user makes a request for data, it is passed through a verification tool before it is displayed to the user in the web application. The components discussed above will be used to create software that adheres to the Model View Presenter (MVP) model, a key part of which is that data is handled and represented in three separate layers. These layers are as follows: Database Layer: where the data used by the software is stored(Model) Presentation Layer: where the data used by the software is displayed(View) Service Layer: where the data used by the software is parsed and verified.(Presenter) This separation of responsibilities surrounding the data into separate layers ensures a level of security with data parsing and makes sure that the data that is displayed is accurate. This configuration is shown in figure 2. Here are two data view modes to display the TLD data: Table ViewThe table view mode is able to provide an organized way to arrange and display the TLD data by using easy-to-read table and grid structure. Chart ViewThe chart view mode allows the user to plot the specific TLD data, and generate the line chart of that data to help the user analyze the properties and tendency of the specific TLD data. TechnologyHere are some technologies and services we choose for this project: Python Environment Python 3.6 (Python is an interpreted, high-level, general-purpose programming language. All the program and components of this project is written in Python) Django 2.2.1 (Django is a high-level Python Web framework. This is the basic of the web application.) - Pip (Package manager for Python. Use it to install other python components or libraries like Virtualenv, awsebcli and Urllib3) Virtualenv (Python Virtual Environment. By using a virtual environment, you can discern exactly which packages are needed by your application so that the required packages are installed on the AWS instances that are running your application.) Awsebcli (Elastic Beanstalk Command Line Interface (EB CLI). This is used to initialize your application with the files necessary for deploying with Elastic Beanstalk.) Urllib3 (urllib3 is a powerful, sanity-friendly HTTP client for Python. We use it to transfer the raw TLD data from the cloud to the local environment) Cloud &amp; Database Services Amazon AWS S3 (Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. This is the simulated cloud environment for this project.) Amazon RDS (Amazon RDS is easy to set up, operate, and scale a relational database in the cloud.)- Amazon Elastic Beanstalk (AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS.) MySQL 5.1 (MySQL is a relational database management system. We use MySQL to manage the database)- Sequel Pro (Sequel Pro is a fast, easy-to-use Mac database management application for working with MySQL databases.) MySQL Workbench (MySQL Workbench is a visual database design tool) Code Editor &amp; IDE Sublime Text 3 (Sublime Text is a proprietary cross-platform source code editor with a Python API. It’s easy to develop code with Sublime Text 3) vim (Vim is a highly configurable text editor built to enable efficient text editing.)","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://blog.david916.com/tags/Django/"},{"name":"Python","slug":"Python","permalink":"http://blog.david916.com/tags/Python/"},{"name":"AWS","slug":"AWS","permalink":"http://blog.david916.com/tags/AWS/"}]},{"title":"Predictions and Countermeasures for the Opioid Crisis with Socio-Economic Factors","slug":"Predictions and Countermeasures for the Opioid Crisis with Socio-Economic Factors","date":"2019-01-28T17:29:00.000Z","updated":"2020-07-20T16:55:43.012Z","comments":true,"path":"2019/01/29/Predictions and Countermeasures for the Opioid Crisis with Socio-Economic Factors/","link":"","permalink":"http://blog.david916.com/2019/01/29/Predictions and Countermeasures for the Opioid Crisis with Socio-Economic Factors/","excerpt":"","text":"SummaryThis project is for the 35th annual Mathematical Contest in Modeling, which won the Honorable Mention amount 16% of the 14,108 participant teams. Full Final ReportSource CodeCertificate In this project, we developed a set of data analyses to determine the opioids source-locations in Ohio, Pennsylvania, Virginia, West Virginia, and Kentucky, to predict the opioids con- sumption trends in years up to 2027, to determine the strongest socio-economic factors that influenced the opioids consumptions trends, and to propose a countermeasure that would possibly ease the Opioid Crisis. First, we processed the data from the drug identification counts by eliminating redun- dant data and by filling the missing data. We chose data values under “Percent” for our future models, because they are the most representative in analyzing opioids consump- tion. We filled the missing data by applying the curve fitting and cubic spline methods to data missing between 20%-50% and under 20%, respectively. Second, with our processed data, we analyzed the locations of the most probable opioid source by utilizing the Bayesian Networks with distance as the determining factor. Graphs representing the locations of several sources are plotted. We then proceed to predict the trends of the top four opioids consumption amount and percentage with Grey Box model. We give a detailed and concise analysis of the opioids types trend. Third, we took account of the impact of major socio-economic factors in opioid con- sumption by increasing efficiency with Principal Component Analysis and by upgrading the previous Grey Box prediction with Vector Autoregression (VAR). VAR allowed us to take account of the socio-economic factors along with the data in opioids consumption in 2010-2017. Last, we proposed that disability is a major factor in determining the opioid con- sumption trend. We performed the VAR with a decreasing factor of 1% each year and observed positive result confirming our proposal. In conclusion, we suggest funding for institutions with opioids rehabilitation as a countering measure against the opioid crisis. We also discussed about the significant parameters that bounds the success and failures of our models, as well as the strengths and weaknesses of our models.","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"R","slug":"R","permalink":"http://blog.david916.com/tags/R/"},{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.david916.com/tags/Data-Science/"},{"name":"Research","slug":"Research","permalink":"http://blog.david916.com/tags/Research/"}]},{"title":"Android Tetris","slug":"Android Tetris","date":"2017-12-06T04:06:00.000Z","updated":"2020-07-20T15:43:38.467Z","comments":true,"path":"2017/12/06/Android Tetris/","link":"","permalink":"http://blog.david916.com/2017/12/06/Android Tetris/","excerpt":"","text":"IntroductionThis is the course project of CS 399 Moblie Application Development. Our final solutions include: Tile rotation and speeding Tile elimination when rows are filled Sound feedback &amp; Background music Final score calculation Speed up the tile falling speed with different difficulty levels Colorful design Source Code Updates2017.12.06 Version 1.0 Final product delievery Demo","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.david916.com/tags/Java/"},{"name":"Android","slug":"Android","permalink":"http://blog.david916.com/tags/Android/"}]},{"title":"iBuy - A Shopping List Android App","slug":"iBuy Shopping List Android App","date":"2017-11-15T03:15:00.000Z","updated":"2020-07-20T16:15:23.450Z","comments":true,"path":"2017/11/15/iBuy Shopping List Android App/","link":"","permalink":"http://blog.david916.com/2017/11/15/iBuy Shopping List Android App/","excerpt":"","text":"IntroductioniBuy is a shopping list Android application. It allows users to list the items they want to buy, marked the price, amount and urgent level of each item, and share your shopping list within a group (family, friend, etc). A household goes through tons of “consumables”: food, toilet paper, laundry detergent, you name it. It is a huge challenge for households to track and manage these daily needs. Though various household members are moving around the city all day — and could potentially make efficient on-the-way purchases — in reality, no one knows or can remember what needs to be purchased and who is supposed to purchase it. Which means wasted time, extra trips to the store for one item, and general frustration about eating dry cereal, washing your hair with facial soap, and wiping your bottom with paper towels. We’ve all been there. Or worse yet, multiple people remember to buy and you end up with 400 rolls of toilet paper. iBuy will solve this problem forever. Source Code Updates2017.11.15 Version 1.0 Final product delievery Demo Register.png AddItem1.png AddItem2.png ShoppingList.png Account.png Group.png Copyright.png","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.david916.com/tags/Java/"},{"name":"Android","slug":"Android","permalink":"http://blog.david916.com/tags/Android/"}]},{"title":"Anagram Game","slug":"Anagram Game","date":"2017-10-11T02:11:00.000Z","updated":"2020-07-31T08:55:13.766Z","comments":true,"path":"2017/10/11/Anagram Game/","link":"","permalink":"http://blog.david916.com/2017/10/11/Anagram Game/","excerpt":"","text":"IntroductionThis is the course project of CS 399 Moblie Application Development. An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. For example, the word anagram can be rearranged into nag a ram, or the word binary into brainy or the word adobe into abode. This android game has 3 different difficulty levels. The game will provide a word and the player will need to enter the correct anagram in order to continue the game. The length of the word will increase with the difficulty of the game. Once the players finish all questions, the game will show a result page with info like the correct rate. Source Code Updates2017.10.10 Version 1.0 Designed and implemented the UI of the game Implemented the game logic and a questions library. Demo main.jpg game.png info.png","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.david916.com/tags/Java/"},{"name":"Android","slug":"Android","permalink":"http://blog.david916.com/tags/Android/"}]},{"title":"Android Calculator App","slug":"Android Calculator App","date":"2017-10-10T02:10:00.000Z","updated":"2020-07-20T15:13:18.768Z","comments":true,"path":"2017/10/10/Android Calculator App/","link":"","permalink":"http://blog.david916.com/2017/10/10/Android Calculator App/","excerpt":"","text":"IntroductionThis is the course project of CS 399 Moblie Application Development. The goal of this project is to develop a calculator android application that provides basic calculation functions like add, subtract, multiply, divide, square root, and percentage. The app has a simple user interface and sounds effect when users click on the button. When first we start to design this app, we try to use the GridLayout to implement the UI of this application. But the problem is the GridLayout in Android is kind of a new thing, which only supports the larger size of the screens. While we try to implement this in a smaller size screen, all of the components went outside of the screen and there is no solution on the internet to solve this problem. Finally, after some research, we decide to use the Tablelayout, which is more flexible to different kinds of devices and reduces the complication of the UI code. It is also flexible in both vertical and landscape views. The whole color design is inspired by the calculator design of the iOS original calculator application. For the division function, it requires the second parameter not to be 0, otherwise, it will throw an error and play the error sound. Another issue is to keep the calculation continuously while we keep pressing the operator button after we got a result. When we first calculate a result, we will store it into a variable and use it as the first parameter of the next calculation. Besides, due to the different sizes of the screens of the devices, we had to limit the digits of the number less than 10. If the digits of the calculation result are greater than 10, we will use the scientific notation to represent the result. APK DownloadSource Code Updates2017.10.10 Version 1.0 Designed and implemented the user interface of the calculator app Developed the calculator function, such as addition, substraction, multiplication and division. Demo","categories":[{"name":"Projects","slug":"Projects","permalink":"http://blog.david916.com/categories/Projects/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.david916.com/tags/Java/"},{"name":"Android","slug":"Android","permalink":"http://blog.david916.com/tags/Android/"}]}]}